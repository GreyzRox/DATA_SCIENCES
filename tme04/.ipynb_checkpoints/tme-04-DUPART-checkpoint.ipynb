{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2024-2025\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUPART Guillaume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-04</tt> et rajouter à la suite de <tt>tme-04</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-04-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le notebook tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font> de votre groupe.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version python et des librairies:\n",
      "\tPython  3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]\n",
      "\tpandas:  2.2.3\n",
      "\tnumpy:  2.2.5\n",
      "\tmatplotlib:  3.10.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanis/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - - - -\n",
    "# imports utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mtpl\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Les instructions suivantes sont utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - -\n",
    "# Information sur l'environnent utilisé ici:\n",
    "print(\"Version python et des librairies:\")\n",
    "print(\"\\tPython \",sys.version)\n",
    "print(\"\\tpandas: \",pd.__version__)\n",
    "print(\"\\tnumpy: \",np.__version__)\n",
    "print(\"\\tmatplotlib: \",mtpl.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'une librairie\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Afin de pouvoir réutiliser les classes et fonctions écrites précédemment dans les séances de TDTME, vous allez construire une librairie avec vos fonctions.\n",
    "\n",
    "Cette librairie, qui s'appellera IADS, contiendra toutes les classes et fonctions que vous allez développer lors de vos séances de TDTME. Elle sera construite donc séance après séance par l'ajout des nouvelles classes et fonctions que vous écrirez.\n",
    "\n",
    "<font color=\"RED\">Important:</font> dans un premier temps, **vous devez écrire les classes et fonctions demandées dans le notebook** de la séance de TDTME courante. A la séance suivante, ou une fois que tout fonctionne correctement, vous rajouterez les classes et fonctions écrites et testées dans vos fichiers de la librairie IADS pour pouvoir réutiliser vos classifieurs par la suite dans les séances suivantes.\n",
    "Attention, lors de la recopie d'un classifieur dans le fichier python de la librairie, il faudra l'adapter.\n",
    "\n",
    "Récupérer et désarchiver l'archive `iads.tgz` de telle sorte que le répertoire `iads` soit un **répertoire frère** du répertoire `tme04`.\n",
    "\n",
    "Ainsi, vous devrez avoir une arborescence qui ressemble à ça:\n",
    "\n",
    "    - LU3IN026/\n",
    "        - tme-01/\n",
    "            - tme-01.ipynb\n",
    "        - tme-02/\n",
    "            - tme-02.ipynb\n",
    "        - tme-03/\n",
    "            - tme-03.ipynb\n",
    "        - tme-04/\n",
    "            - tme-04.ipynb\n",
    "        - iads/\n",
    "            - Classifiers.py\n",
    "            - Clustering.py\n",
    "            - utils.py\n",
    "            - evaluation.py\n",
    "            - __init__.py\n",
    "          \n",
    "\n",
    "<b>Important</b> :\n",
    "- ce fichier `tme-04.ipynb` doit toujours rester dans le répertoire `tme-04/`\n",
    "- pour ouvrir les fichiers python (extension .py) qui se trouvent dans le répertoire iads/ il est nécessaire d'utiliser un éditeur de texte comme emacs, gedit, idle,...\n",
    "</div>\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Ouvrir et compléter les fichiers Classifiers.py et utils.py**\n",
    "\n",
    "Pour compléter ces fichiers, reprendre le code écrit dans les TDTME précédents.\n",
    "- dans `utils.py`: `genere_dataset_uniform`, `genere_dataset_gaussian`, `plot2DSet`, `plot_frontiere` et `create_XOR`\n",
    "- dans `Classifiers.py`: reprendre le code des classifiers que vous avez déjà définis.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Mise à jour de la librairie `iads`**\n",
    "\n",
    "En premier lieu, vérifier que votre librairie `iads` est bien à jour : elle doit maintenant contenir toutes les fonctions et classes que mises au point et testées dans les séances précédentes. Une fois à jour, importer la librairie pour pouvoir l'utiliser dans ce notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01miads\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01miads\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# importation de Classifiers\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01miads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Classifiers \u001b[38;5;28;01mas\u001b[39;00m classif\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# importation de utils\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01miads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m ut\n",
      "File \u001b[0;32m~/Documents/Sciences_des_donn-es_L3/tme04/../iads/Classifiers.py:295\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m-\u001b[39mprecedent_w)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m#######################################################################################\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClassifierMultiOAA\u001b[39;00m(\u001b[43mclassif\u001b[49m\u001b[38;5;241m.\u001b[39mClassifier):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124;03m\"\"\" Classifieur multi-classes\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cl_bin):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classif' is not defined"
     ]
    }
   ],
   "source": [
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Attention:</b> à partir d'ici, lorsque vous voulez utiliser un algorithme qui se trouve dans le fichier `Classifier.py` il est nécessaire de préfixer son nom par `classif.` qui est le nom du fichier de la librairie. Pour utiliser une fonction du fichier `utils.py`, il faut préfixer le nom de la fonction par `ut.`\n",
    "\n",
    "\n",
    "Dans les boîtes qui vont suivre, on appliquera ce principe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARQUE: une fois les importations faites, les fonctions de utils sont utilisables\n",
    "#  en mettant ut. devant leur nom:\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "d_desc_gauss, d_lab_gauss = ut.genere_dataset_gaussian(np.array([1,1]) ,np.array([[1,0],[0,1]]), \\\n",
    "                                                       np.array([-0.5,-1]), np.array([[1,0],[0,1]]), \\\n",
    "                                                       100)\n",
    "\n",
    "print(\"Taille du dataset généré :\", np.shape(d_desc_gauss), \"exemples\")\n",
    "\n",
    "# Affichage :\n",
    "ut.plot2DSet(d_desc_gauss,d_lab_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d_desc_gauss\n",
    "label = d_lab_gauss\n",
    "\n",
    "# Réinitialisation de la graine pour la mise au point (à enlever ensuite !)\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# De même, les classes de Classifiers sont utilisables en mettant classif. devant leur nom:\n",
    "# Création d'un perceptron\n",
    "perceptron1 = classif.ClassifierPerceptron(2, learning_rate=0.01, init=True)\n",
    "\n",
    "perceptron1.train(data, label)\n",
    "print(\"Accuracy : \", perceptron1.accuracy(data,label))\n",
    "\n",
    "# Affichage de la frontière de séparation des classes\n",
    "ut.plot_frontiere(data,label,perceptron1,step=60)\n",
    "ut.plot2DSet(data,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà, à partir de maintenant, vous pourrez donc ainsi réutiliser dans vos notebooks des classes et des fonctions écrites précédemment sans avoir à recopier tout le code implémenté !\n",
    "\n",
    "Dans les prochains notebooks, vous mettrez au point les fonctions et classes demandées et une fois qu'elles seront au point et validées, vous pourrez les transférer dans votre librairie IADS pour pouvoir les réutiliser dans les séances suivantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Pour étudier la convergence du perceptron, on a besoin de garder une trace de tous les poids $w$ qui ont été utilisés. Pour cela, rajouter à la classe `ClassifierPerceptron` un attribut de nom `allw` qui est initialisé aux poids initiaux dans `__init__` par:\n",
    "\n",
    "    self.allw =[self.w.copy()] # stockage des premiers poids\n",
    "        \n",
    "cet attribut est à mettre jour pendant l'entraînement `train_step` du perceptron, **après chaque mise à jour des poids**. \n",
    "\n",
    "<b>Remarque</b>: attention ! pour copier le vecteur $w$ penser à faire une copie profonde...\n",
    "\n",
    "\n",
    "Ajouter aussi dans la classe un accesseur `get_allw()` pour récupérer la valeur de `allw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utiliser une fois la classe ClassifierPerceptron modifiée par l'ajout de allw\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = 2\n",
    "eps = 5e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Réinitialisation de la graine pour la mise au point (à enlever ensuite !)\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "perceptron2 = classif.ClassifierPerceptron(dim, learning_rate=eps, init=poids_0)\n",
    "\n",
    "les_differences = perceptron2.train(data, label,nb_max=100)\n",
    "\n",
    "# récupération de l'évolution des w au cours de l'apprentissage \n",
    "# perceptron initialisé à 0\n",
    "# si allw est sous forme de liste de couples [w1, w2], on doit la convertir en np.array pour la suite:\n",
    "allw = np.array(perceptron2.get_allw()) \n",
    "\n",
    "# Tracé de l'évolution des w:\n",
    "plt.figure()\n",
    "plt.plot(allw[:,0]) # première coordonnée du vecteur poids: w1\n",
    "plt.plot(allw[:,1]) # deuxième coordonnée du vecteur poids: w2\n",
    "plt.title('Evolution des w')\n",
    "plt.xlabel('Nombre de modifications')\n",
    "plt.legend(['w1','w2'])\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous et créer le sous-répertoire out/):\n",
    "plt.savefig('out/cvg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compléments sur le perceptron\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Afin d'améliorer notre classifieur perceptron, nous allons considérer une version modifiée de la classe `ClassifierPerceptronBiais`, que nous appellerons `ClassifierPerceptronBiais` pour construire un perceptron en utilisant un <b>biais</b> qui facilite la convergence du modèle: pour déterminer si une mise à jour des poids doit être faite, le critère de mauvaise classification est remplacé par\n",
    "$$ f(\\mathbf x_i) y_i < 1 $$\n",
    "où $f(\\mathbf x_i)$ est le score obtenu pour $x_i$.\n",
    "\n",
    "<b>Idée</b>: on veut que $f(\\mathbf x_i)$ et $y_i$ soient du même signe ET que $f(\\mathbf x_i)$ soit suffisamment grand (en valeur absolue).\n",
    "    \n",
    "C'est une version dite *stabilisée* du perceptron où les points ne sont considérés bien classés que lorsque $f(\\mathbf x_i) y_i \\geq 1$. Dans le cas contraire, on met à jour les poids.\n",
    "\n",
    "La mise à jour des poids tient alors compte de ce biais: $$ w = w +\\epsilon (y_i- f(\\mathbf x_i))x_i.$$\n",
    "\n",
    "</div>    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la classe `ClassifierPerceptronBiais` (tout d'abord dans une boîte de ce notebook, puis vous la copierez dans votre fichier `Classifiers.py`) et tester le code suivant qui doit être fonctionnel. \n",
    "\n",
    "Pour éviter d'avoir à récrire les fonctions déjà écrites pour le perceptron et qui ne changeront pas dans le cas du perceptron avec biais, on fait hériter la classe `ClassifierPerceptronBiais` de la classe `ClassifierPerceptron`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "\n",
    "# Remarque : quand vous transférerez cette classe dans le fichier classifieur.py \n",
    "# de votre librairie, il faudra enlever \"classif.\" en préfixe de la classe ClassifierPerceptron:\n",
    "\n",
    "class ClassifierPerceptronBiais(classif.ClassifierPerceptron):\n",
    "    \"\"\" Perceptron de Rosenblatt avec biais\n",
    "        Variante du perceptron de base\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dimension, learning_rate=0.01, init=True):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - input_dimension (int) : dimension de la description des exemples (>0)\n",
    "                - learning_rate (par défaut 0.01): epsilon\n",
    "                - init est le mode d'initialisation de w: \n",
    "                    - si True (par défaut): initialisation à 0 de w,\n",
    "                    - si False : initialisation par tirage aléatoire de valeurs petites\n",
    "        \"\"\"\n",
    "        # Appel du constructeur de la classe mère\n",
    "        super().__init__(input_dimension, learning_rate, init)\n",
    "        # Affichage pour information (décommentez pour la mise au point)\n",
    "        # print(\"Init perceptron biais: w= \",self.w,\" learning rate= \",learning_rate)\n",
    "        \n",
    "    def train_step(self, desc_set, label_set):\n",
    "        \"\"\" Réalise une unique itération sur tous les exemples du dataset\n",
    "            donné en prenant les exemples aléatoirement.\n",
    "            Arguments:\n",
    "                - desc_set: ndarray avec des descriptions\n",
    "                - label_set: ndarray avec les labels correspondants\n",
    "        \"\"\"  \n",
    "        combined = list(zip(desc_set, label_set))\n",
    "        np.random.shuffle(combined)\n",
    "        shuffle_set,shuffle_label = zip(*combined)\n",
    "        shuffle_set = np.array(shuffle_set)\n",
    "        shuffle_label = np.array(shuffle_label) \n",
    "        \n",
    "        precedent_w = self.w.copy()\n",
    "        \n",
    "        for xi, yi in zip(shuffle_set, shuffle_label):\n",
    "            yi_dot= self.score(xi) # Calcul du score\n",
    "            if yi_dot < 1:\n",
    "                self.w += self.lrate*(yi - yi_dot)*xi\n",
    "                self.allw.append(self.w.copy())\n",
    "            \n",
    "        return np.linalg.norm(self.w-precedent_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = 2\n",
    "eps = 5e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Création et entraînement du perceptron sur les données générées\n",
    "\n",
    "# -------------------------------\n",
    "#### ATTENTION : commenter la ligne qui correspond à votre cas :\n",
    "\n",
    "## La classe ClassifierPerceptronBiais a été mise dans Classifier.py :\n",
    "perc = classif.ClassifierPerceptronBiais(dim, eps)\n",
    "\n",
    "## La classe ClassifierPerceptronBiais se trouve dans ce notebook :\n",
    "#perceptron_biais = ClassifierPerceptronBiais(dim, learning_rate=eps, init=poids_0)\n",
    "# -------------------------------\n",
    "\n",
    "les_differences = perc.train(data, label)\n",
    "\n",
    "# récupération de l'évolution des w au cours de l'apprentissage \n",
    "# perceptron initialisé à 0\n",
    "# si allw est sous forme de liste de couples [w1, w2], on doit la convertir en np.array pour la suite:\n",
    "allw = np.array(perc.get_allw()) \n",
    "\n",
    "# Tracé de l'évolution des w:\n",
    "plt.figure()\n",
    "plt.plot(allw[:,0]) # première coordonnée du vecteur poids: w1\n",
    "plt.plot(allw[:,1]) # deuxième coordonnée du vecteur poids: w2\n",
    "plt.title('Evolution des w')\n",
    "plt.xlabel('Nombre de modifications')\n",
    "plt.legend(['w1','w2'])\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "# et créer un répertoire out/ dans le répertoire tme04\n",
    "# puis aller dans le répertoire `out` avec un navigateur de fichiers (ou par le terminal)\n",
    "# pour visualiser l'image obtenue par :\n",
    "\n",
    "plt.savefig('out/cvg1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Remarque</b>: dans ce qui suit, on considére que la classe `ClassifierPerceptronBiais` se trouve dans ce notebook, pensez à corriger si vous avez déplacé votre classe dans `Classifiers.py` de votre librairie IADS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lien avec l'optimisation des fonctions de coût\n",
    "\n",
    "Après ces rappels de code, nous entrons maintenant dans le vif du sujet !\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "L'évolution des poids du perceptron correspond en réalité à l'optimisation de la fonction coût suivante (cela sera développé en cours):\n",
    "\n",
    "$$ \\mathcal C = \\sum_{i=1}^N [1- f(\\mathbf x_i) y_i]_+, \\qquad \\mbox{avec: } \n",
    "[\\alpha]_+ = \\left\\{\\begin{array}{ll}\n",
    "\\alpha & \\mbox{ si } \\alpha >0\\\\\n",
    "0 & \\mbox{ sinon }\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "Nous utilisons ici une version *stabilisée* du perceptron où les points ne sont bien classé que lorsque \n",
    "$f(\\mathbf x_i) y_i>1$\n",
    "\n",
    "Le perceptron est une simple descente de gradient.\n",
    "\n",
    "Deux questions se posent alors :\n",
    "1. Quelle est l'évolution de $\\mathcal C$ au cours des itérations ?\n",
    "1. Quel chemin de variations prennent les $w$ dans le cas 2D ?\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Donner les instructions qui permettent de tracer l'évolution du coût \n",
    "$\\mathcal{C}$ au cours des itérations lors de l'apprentissage précédent. Pour cela, vous utiliserez les valeurs de $w$ sauvegardées lors de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toujours avec les mêmes données :\n",
    "X = data\n",
    "Y = label\n",
    "\n",
    "# on considère les poids de perceptron_biais généré dans une boite précédente:\n",
    "allw = np.array(perc.get_allw()) \n",
    "\n",
    "# ############### \n",
    "C = []\n",
    "for w in allw:\n",
    "    a = 1-np.dot(X,w)*Y\n",
    "    a[a<=0] = 0\n",
    "    C.append(np.sum(a))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# ############### \n",
    "\n",
    "# --------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(C)\n",
    "plt.title('Evolution du coût')\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "plt.savefig('out/cost.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution des poids dans l'espace des paramètres\n",
    "\n",
    "Le code pour étudier l'évolution des poids dans l'espace des paramères est presque entièrement donné ci-dessous... Sauf une ligne critique !\n",
    "\n",
    "<b>Remarque</b>: il faut absolument comprendre la signification du code et de l'image produite.\n",
    "\n",
    "Pour cela, regarder la documentation des fonctions\n",
    "- `numpy.meshgrid` : https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html\n",
    "- `numpy.linspace` : https://numpy.org/doc/stable/reference/generated/numpy.linspace.html\n",
    "- `matplotlib.pyplot.scatter` : : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution des poids dans l'espace des paramètres\n",
    "# le code est presque entièrement donné... Sauf une ligne critique\n",
    "# Il faut absolument comprendre la signification du code et de l'image produite\n",
    "\n",
    "# 1. Construction d'une grille de 'toutes' les valeurs possibles de w dans les bornes de allw\n",
    "mmax=allw.max(0)\n",
    "mmin=allw.min(0)\n",
    "x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],30),np.linspace(mmin[1],mmax[1],30))\n",
    "grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
    "\n",
    "# 2. Evaluation du cout pour toutes ces solutions potentielles\n",
    "\n",
    "##########\n",
    "# LIGNE A COMPLETER:\n",
    "# construction de res = calcul du cout du perceptron pour tous les couples\n",
    "# (w1,w2) définis dans grid\n",
    "\n",
    "res = np.zeros(grid.shape[0])\n",
    "for idx, w in enumerate(grid):\n",
    "    cost = 0\n",
    "    for i in range(len(X)):\n",
    "        score = np.dot(X[i], w)\n",
    "        if Y[i] * score < 1:\n",
    "            cost += 1 - Y[i] * score\n",
    "    res[idx] = cost\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "# remise en forme de res\n",
    "res=res.reshape(x1grid.shape) \n",
    "\n",
    "fig, ax = plt.subplots() # pour 1 et 2\n",
    "ax.set_xlabel('$w_1$')\n",
    "ax.set_ylabel('$w_2$')\n",
    "CS = ax.contour(x1grid,x2grid,res)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "# ajoute de la couleur: jaune = plus grande itération\n",
    "ax.scatter(allw[:,0], allw[:,1], c=np.arange(len(allw)))\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "plt.savefig(\"out/espace_param.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solution initiale $w=[0,0]$ correspond à un coût élevé. L'algorithme du perceptron fait évoluer les poids du modèle pour aller dans une zone de l'espace où le coût est moindre.\n",
    "\n",
    "**ATTENTION** à ne pas confondre l'espace de représentation des points (où les axes sont $X_1,X_2$) et l'espace de représentation des paramètres (ici, où chaque point correspond à un classifieur associé à un niveau de coût)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Croisée\n",
    "\n",
    "Dans le but d'évaluer un classifier, nous avons vu dans le TME 3 qu'il était important de posséder un ensemble de données de test, différent de l'ensemble d'apprentissage.\n",
    "\n",
    "Nous allons voir maintenant une méthode encore plus efficace pour bien évaluer un algorithme.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "La procédure de la <b>validation croisée</b> (ou <i>cross validation</i>) est au centre de la plupart des applications de machine learning: il est temps pour nous de travailler sur une implémentation.\n",
    "\n",
    "L'idée est de concevoir la fonction suivante:\n",
    "```\n",
    "Xapp,Yapp,Xtest,Ytest = crossval(X, Y, n_iterations, iteration)\n",
    "```\n",
    "- ```X, Y``` sont les données du dataset **mélangées aléatoirement** (on ne mélange pas physiquement les données, mais seulement leurs indices)\n",
    "- ```n_iterations``` est le nombre d'ensembles de test au total.\n",
    "- ```iteration``` est l'itération concernée: on ne renvoit pas les mêmes données en fonction des itérations.\n",
    "\n",
    "Après séparation des indices en ```n_iterations``` groupes, isoler 1 groupe pour le test et les autres pour l'apprentissage.\n",
    "\n",
    "\n",
    "<b>Remarques:</b>\n",
    "- on fait l'hypothèse que le dataset (`X`, `Y`) garde toujours le même ordre entre 2 appels de `crossval` successif avec des valeurs d'itération différentes.\n",
    "- cette fonction ne doit pas mélanger les données du dataset fourni (qui doit être mélangé au préalable), elle sert juste à extraire de ce dataset 2 sous-datasets: un dataset d'apprentissage (`Xapp`, `Yapp`) et un dataset de test (`Xtest`, `Ytest`).\n",
    "- elle extrait les datasets demandés comme suit:\n",
    "    - le dataset de test pour l'itération $i$ contient les exemples du dataset $X$ dont les indices vont de $i\\frac{len(X)}{n}$ à  $(i+1)\\frac{len(X)}{n}-1$ (avec $n$ le nombre d'itérations `n_iterations` fixé).\n",
    "    - le dataset d'apprentissage pour l'itération $i$ contient les exemples du dataset $X$ contient les exemples qui ne sont pas dans le dataset de test.\n",
    "\n",
    "</div>    \n",
    "    \n",
    "**Note** Pour mélanger les données au départ, avant le premier appel de `crossval`, vous pouvez utiliser les commandes suivantes:\n",
    "```\n",
    "index = np.random.permutation(len(X)) # mélange des index\n",
    "Xm = X[index]\n",
    "Ym = Y[index]\n",
    "\n",
    "# check: malgré le mélange, les données doivent être les mêmes\n",
    "plt.figure()\n",
    "plt.scatter(Xm[Ym==1,0], Xm[Ym==1,1], c='b')\n",
    "plt.scatter(Xm[Ym==-1,0], Xm[Ym==-1,1], c='r')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Donner la définition de la fonction `crossval` telle qu'elle est décrite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(X, Y, n_iterations, iteration):\n",
    "    start = int(iteration *(X.shape[0]//n_iterations))\n",
    "    end = int((iteration + 1) *(X.shape[0]//n_iterations))\n",
    "    Xtest = X[start:end]\n",
    "    Ytest = Y[start:end]\n",
    "    Xapp = np.concatenate((X[:start],X[end:]))\n",
    "    Yapp = np.concatenate((Y[:start],Y[end:]))\n",
    "\n",
    "    return Xapp, Yapp, Xtest, Ytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarder l'exemple d'utilisation suivant, sur un dataset jouet, pour comprendre comment sont pris les exemples à chaque appel différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour vérifier que le traitement est bien réalisé et que tout marche bien \n",
    "# en particulier (très important !) que le lien entre descriptions X et classes Y n'est pas perdu,\n",
    "# on peut regarder ce qui se passe si X et Y sont les mêmes:\n",
    "\n",
    "N = 24  # Nombre d'exemples dans le dataset\n",
    "Xjouet = np.array([i for i in range(0,N)])   \n",
    "Yjouet = Xjouet  # Yjouet est identique à Xjouet\n",
    "\n",
    "niter = 4\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval(Xjouet, Yjouet, niter, i)\n",
    "    print(\"========== ITERATION : \",i,\" ==========\")\n",
    "    print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)\n",
    "    \n",
    "    \n",
    "print(\"\\n*********************\\nEt on peut rappeler la fonction avec 0 par exemple: \")    \n",
    "Xapp,Yapp,Xtest,Ytest = crossval(Xjouet, Yjouet, niter, 0)\n",
    "print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> En fait, pour faire les choses correctement, il faut que la séparation des ensembles train/test respecte la distribution des classes dans le dataset de départ. Ecrire la fonction `crossval_strat` qui effectue la même chose que la fonction précédente mais en respectant la distribution des classes. La solution passe par un découpage qui s'effectue par classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de la validation croisée (version qui respecte la distribution des classes)\n",
    "\n",
    "def crossval_strat(X, Y, n_iterations, iteration):\n",
    "    classe = np.unique(Y) \n",
    "    indices_classe = {c: np.where(Y==c)[0] for c in classe}\n",
    "    test_indices= []\n",
    "    train_indices =[]\n",
    "    for c in classe:\n",
    "        indices = indices_classe[c]  # Indices de la classe actuelle\n",
    "        taille_test = len(indices) // n_iterations \n",
    "        start =iteration*taille_test\n",
    "        end=(iteration+1)*taille_test\n",
    "        test_indices.extend(indices[start:end]) \n",
    "        train_indices.extend(np.concatenate((indices[:start], indices[end:]))) \n",
    "\n",
    "    Xtest,Ytest=X[test_indices],Y[test_indices]\n",
    "    Xapp,Yapp=X[train_indices],Y[train_indices]\n",
    "    return Xapp, Yapp, Xtest, Ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec un dataset jouet (1 Dimension)\n",
    "N = 24  # Nombre d'exemples dans le dataset\n",
    "#Xtoy = np.arange(N).reshape(N,1)\n",
    "Xtoy = np.array([i for i in range(0,N)])   \n",
    "Ytoy = np.array([-1]*(N//2) + [1]*(N//2))\n",
    "#index = np.random.permutation(len(Xtoy)) # mélange des index\n",
    "#XtoyMelange = Xtoy[index]\n",
    "#YtoyMelange = Ytoy[index]\n",
    "\n",
    "niter = 3\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(Xtoy, Ytoy, niter, i)\n",
    "    print(\"========== ITERATION : \",i,\" ==========\")\n",
    "    print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: il est important, avant d'utiliser `crossval` ou `crossval_strat` de mélanger le dataset. Ce mélange aléatoire doit être fait une seule fois avant le premier appel de la fonction (et jamais entre 2 appels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Exemple d'utilisation avec un dataset jouet (1 Dimension)\n",
    "N = 24  # Nombre d'exemples dans le dataset\n",
    "Xtoy = np.array([i for i in range(0,N)])   \n",
    "Ytoy = np.array([-1]*(N//2) + [1]*(N//2))\n",
    "index = np.random.permutation(len(Xtoy)) # mélange des index\n",
    "XtoyMelange = Xtoy[index]\n",
    "YtoyMelange = Ytoy[index]\n",
    "\n",
    "niter = 3\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(XtoyMelange, YtoyMelange, niter, i)\n",
    "    print(\"========== ITERATION : \",i,\" ==========\")\n",
    "    print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de la procédure de validation croisée \n",
    "\n",
    "Sur des données réelles et sur des données jouets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "# test sur les données jouet X, Y supposées pré-existantes\n",
    "\n",
    "index = np.random.permutation(len(X)) # mélange des index\n",
    "Xm = X[index]\n",
    "Ym = Y[index]\n",
    "niter = 10\n",
    "perf = []\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = 2\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval(Xm, Ym, niter, i)\n",
    "    perceptron4 = ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "    perceptron4.train(Xapp, Yapp)\n",
    "    perf.append(perceptron4.accuracy(Xtest, Ytest))\n",
    "    \n",
    "print(\"Performances obtenues: \",perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Tester la validation croisée sur les données USPS avec le perceptron biais.\n",
    "\n",
    "**Remarque:** pour utiliser les données USPS, il vous faut\n",
    "- soit créer un lien symbolique (cf. TME 3) vers le sous-répertoire `data` du TME 2 qui contient le fichier `usps.pkl` du TME 2\n",
    "- soit modifier le nom du fichier dans la commande `open` du code ci-dessous en mettant le chemin d'accès vers l'endroit où se trouve votre fichier `usps.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sur les données USPS\n",
    "import pickle as pkl\n",
    "\n",
    "data = pkl.load(open('../tme02/data/usps.pkl', 'rb'))\n",
    "Xu = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Yu = np.array(data['Y_train'], dtype=float)\n",
    "\n",
    "# Création d'un sous groupe de données\n",
    "c1 = 4  # ---> sera associée au label +1  \n",
    "c2 = 6  # ---> sera associée au label -1\n",
    "X12 = Xu[(Yu==c1) | (Yu==c2)]\n",
    "Y12 = np.where(Yu[(Yu==c1) | (Yu==c2)]==c1, 1, -1)\n",
    "\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = X12.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "# Liste pour stocker les taux de bonne classification à chaque itération\n",
    "perf = []\n",
    "\n",
    "# ######################## A COMPLETER CI-DESSOUS\n",
    "# 1) mélanger des exemples \n",
    "index = np.random.permutation(len(X12)) # mélange des index\n",
    "X12_melange = X12[index]\n",
    "Y12_melange = Y12[index]\n",
    "\n",
    "# 2) réaliser une validation croisée complète \n",
    "\n",
    "for i in range(nb_iter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(X12_melange, Y12_melange, nb_iter, i)\n",
    "    perceptron5 = classif.ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "    perceptron5.train(Xapp, Yapp)\n",
    "    perf.append(perceptron5.accuracy(Xtest, Ytest))\n",
    "    print(\"Itération \",i,\" : taille base app= \",Xapp.shape[0],\" taille base test= \",Xtest.shape[0],\" Taux de bonne classif: \",perceptron5.accuracy(Xtest, Ytest))\n",
    "\n",
    "# Résultat final:\n",
    "print(\"Performances obtenues : \",perf)\n",
    "mean_perf = np.mean(perf)\n",
    "print(f\"Taux de bonne classification moyen sur {nb_iter} itérations : {mean_perf:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(9).reshape((3, 3))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Pour évaluer un classifieur, on regarde la moyenne et l'écart type de son taux de bonne classification lors d'une validation croisée.\n",
    "\n",
    "Ecrire la fonction `analyse_perfs` qui prend en argument une liste de nombres réels (non vide) et renvoie le tuple constitué de la moyenne et de l'écart type de ces nombres.\n",
    "\n",
    "**Remarque**: l'écart type donne une information sur la \"robustesse\" du modèle. Plus il est grand, est plus cela signifie que la performance du classifieur dépend du jeu d'apprentissage qui a servi à le construire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER\n",
    "def analyse_perfs(L):\n",
    "    \"\"\" L : liste de nombres réels non vide\n",
    "        rend le tuple (moyenne, écart-type)\n",
    "    \"\"\"\n",
    "    # np.std rend l'écart type\n",
    "    return (np.mean(L), np.std(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sur les résultats obtenus dans la boîte précédemment:\n",
    "analyse_perfs(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Quelle information apporte ici l'écart type ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'écart type est très faible donc cela veut dire que le classifieur est bien construit et qu'il ne dépend pas du jeu d'apprentissage.qui a servi à le construire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des classifieurs knn, perceptron et perceptron biais\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Comparer les performances sur le jeu de données USPS (par exemple, en prenant le label 1 et le label 7 pour avoir 2 classes), par une validation croisée en 10 groupes, de tous les classifieurs que vous avez déjà implémentés. Que peut-on en conclure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sur les données USPS\n",
    "import pickle as pkl\n",
    "\n",
    "data = pkl.load(open('../tme02/data/usps.pkl', 'rb'))\n",
    "Xu = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Yu = np.array(data['Y_train'], dtype=float)\n",
    "\n",
    "# Création d'un sous groupe de données\n",
    "c1 = 1  # ---> sera associée au label +1  \n",
    "c2 = 7  # ---> sera associée au label -1\n",
    "X12 = Xu[(Yu==c1) | (Yu==c2)]\n",
    "Y12 = np.where(Yu[(Yu==c1) | (Yu==c2)]==c1, 1, -1)\n",
    "\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = X12.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "k = 5   # k pour le KNN\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "# Liste pour stocker les taux de bonne classification à chaque itération\n",
    "perf_knn = []\n",
    "perf_random = []\n",
    "perf_percep = []\n",
    "perf_percep_biais = []\n",
    "\n",
    "# ######################## A COMPLETER CI-DESSOUS\n",
    "index = np.random.permutation(len(X12)) # mélange des index\n",
    "X12_melange = X12[index]\n",
    "Y12_melange = Y12[index]\n",
    "\n",
    "print(\"Avec KPPV (k=\",k,\") :\")\n",
    "for i in range(nb_iter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(X12_melange, Y12_melange, nb_iter, i)\n",
    "    knn = classif.ClassifierKNN(dim, k)\n",
    "    knn.train(Xapp,Yapp)\n",
    "    perf_knn.append(knn.accuracy(Xtest, Ytest))\n",
    "knn_moy,knn_std = analyse_perfs(perf_knn)\n",
    "print(\"        Moyenne:\",knn_moy,\" ecart: \",knn_std,\"\\n\")\n",
    "\n",
    "print(\"Avec classifieur linéaire random:\")\n",
    "for i in range(nb_iter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(X12_melange, Y12_melange, nb_iter, i)\n",
    "    random = classif.ClassifierLineaireRandom(dim)\n",
    "    random.train(Xapp,Yapp)\n",
    "    perf_random.append(random.accuracy(Xtest, Ytest))\n",
    "random_moy,random_std = analyse_perfs(perf_random)\n",
    "print(\"        Moyenne:\",random_moy,\" ecart: \",random_std,\"\\n\")\n",
    "\n",
    "print(\"Avec perceptron (init w=0):\")\n",
    "for i in range(nb_iter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(X12_melange, Y12_melange, nb_iter, i)\n",
    "    percep = classif.ClassifierPerceptron(dim, eps, poids_0)\n",
    "    percep.train(Xapp,Yapp)\n",
    "    perf_percep.append(percep.accuracy(Xtest, Ytest))\n",
    "percep_moy,percep_std = analyse_perfs(perf_percep)\n",
    "print(\"        Moyenne:\",percep_moy,\" ecart: \",percep_std,\"\\n\")\n",
    "\n",
    "print(\"Avec perceptron biais (init w=0):\")\n",
    "for i in range(nb_iter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(X12_melange, Y12_melange, nb_iter, i)\n",
    "    percep_biais = classif.ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "    percep_biais.train(Xapp, Yapp)\n",
    "    perf_percep_biais.append(percep_biais.accuracy(Xtest, Ytest))\n",
    "percep_biais_moy,percep_biais_std = analyse_perfs(perf_percep_biais)\n",
    "print(\"        Moyenne:\",percep_biais_moy,\" ecart: \",percep_biais_std,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plus loin avec le multi-classes\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Le perceptron est un algorithme fondamentalement bi-classes: il est même lié à la manière dont sont encodées les étiquettes $\\{+1,-1\\}$. La plupart des problèmes réels sont pourtant multi-classes (e.g. USPS).\n",
    "Si cet algorithme a pu rester aussi classique, c'est qu'il existe un moyen d'étendre un classifieur binaire en une extension multi-classes simple et efficace: le *un-contre-tous* (ou *One-Against-All* en anglais):\n",
    "    \n",
    "<i>(si l'image ci-dessous ne s'affiche pas, aller la voir dans le répertoire ressources)</i>\n",
    "\n",
    "<img src=\"ressources/multi2.png\">\n",
    "\n",
    "    \n",
    "Dans l'approche *un-contre-tous* l'idée est d'apprendre autant de classifieurs binaires que de classes. \n",
    "\n",
    "Dans l'exemple ci-dessus, cela donne:\n",
    "\n",
    "1. Traitement de la classe 0\n",
    "1. redéfinition de:\n",
    "$$Y_{tmp} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{ si } Y = 0\\\\ -1 & \\text{ si } Y \\neq 0\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "1. apprentissage de $f_0$ sur $X,Y_{tmp}$\n",
    "1. Traitement de la classe 1\n",
    "1. redéfinition de:\n",
    "$$Y_{tmp} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{ si } Y = 1\\\\\n",
    "-1 & \\text{ si } Y \\neq 1\\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "1. apprentissage de $f_1$ sur $X,Y_{tmp}$\n",
    "1. etc...\n",
    "\n",
    "\n",
    "En inférence, lorsqu'un nouveau point $\\mathbf x$ est présenté il faut:\n",
    "1. calculer $score = [f_0(\\mathbf x),  f_1(\\mathbf x), \\ldots f_C(\\mathbf x)]$\n",
    "1. prédire $\\text{argmax}_c (score)$\n",
    "\n",
    "<br>\n",
    "\n",
    "Pour implémenter cela, on ne va pas définir une version multi-classe pour chaque classifieur binaire que l'on a écrit, cela ne serait pas de la programmation efficace...\n",
    "On va définir un nouveau classifieur générique multi-classes qui utilisera un classifieur binaire (en POO, on va se baser sur le *pattern composite*) en respectant le schéma suivant:\n",
    "\n",
    "1. ```ClassifierMultiOAA``` prend un classifieur binaire en argument lors de la création. Il initialise une liste vide de classifieurs.\n",
    "\n",
    "1. Dans la méthode ```train```, penser à cloner le classifeur de référence ```nCl``` fois (autant de classifieurs que de classes dans la base d'apprentissage).\n",
    "Il faut utiliser la méthode ```deepcopy``` du module standard python ```copy```\n",
    "\n",
    "1. Dans un boucle for, redéfinir les étiquettes $ytmp$ et apprendre des classifieurs binaires\n",
    "\n",
    "1. Dans ```score``` faire appel aux méthodes ```score``` des classifieurs binaires et stocker les résultats\n",
    "\n",
    "1. Dans ```predict``` renvoyer l'argmax des scores.<BR>\n",
    "**Note:** en faisant cette opération, on fait l'hypothèse que les étiquettes sont définies sur $[0,nCl]$. Pour lever cette hypothèse, il faudrait stocker les classes et convertir le résultat de argmax.\n",
    "\n",
    "    \n",
    "**Important:**\n",
    "La fonction ```accuracy``` de la classe mère doit être compatible avec les définitions précédentes... Par exemple:\n",
    "```\n",
    "def accuracy(self, desc_set, label_set):\n",
    "        yhat = np.array([self.predict(x) for x in desc_set])\n",
    "        return np.where(label_set == yhat, 1., 0.).mean()\n",
    "```\n",
    "\n",
    " <b>Attention:</b> on fait ici l'hypothèse que l'on ne considère que des classes numérotées de $0$ à $9$, comme celles dans USPS. Ainsi, le premier classifieur reconnaît la classe $0$ contre toutes les autres, le deuxième classifieur reconnaît la classe $1$ contre les autres, etc.\n",
    "Pour une solution plus générale, la fonction `predict` ne devra pas rendre l'indice du maximum (argmax) mais la classe qui correspond à ce maximum.\n",
    "    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donner la définition de la classe ClassifierMultiOAA\n",
    "\n",
    "# Vous pouvez avoir besoin d'utiliser la fonction deepcopy de la librairie standard copy:\n",
    "import copy \n",
    "\n",
    "class ClassifierMultiOAA(classif.Classifier):\n",
    "    \"\"\" Classifieur multi-classes\n",
    "    \"\"\"\n",
    "    def __init__(self, cl_bin):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - input_dimension (int) : dimension de la description des exemples (espace originel)\n",
    "                - cl_bin: classifieur binaire positif/négatif\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.classifieur_binaire = cl_bin\n",
    "        self.classifieurs = []\n",
    "        self.classes = None\n",
    "        \n",
    "        \n",
    "    def train(self, desc_set, label_set):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "            réalise une itération sur l'ensemble des données prises aléatoirement\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"        \n",
    "        self.classes = np.unique(label_set)\n",
    "        nCl = len(self.classes)\n",
    "\n",
    "        for i in range(nCl):\n",
    "            classif = copy.deepcopy(self.classifieur_binaire)\n",
    "\n",
    "            ytmp = np.where(label_set == self.classes[i], 1, -1)\n",
    "            classif.train(desc_set,ytmp)\n",
    "            self.classifieurs.append(classif)\n",
    "        \n",
    "    \n",
    "    def score(self,x):\n",
    "        \"\"\" rend le score de prédiction sur x (valeur réelle)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        return np.array([classifieur.score(x) for classifieur in self.classifieurs])\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\" rend la prediction sur x (soit -1 ou soit +1)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        scores = self.score(x)\n",
    "        classe_predite_index = np.argmax(scores)\n",
    "        return self.classes[classe_predite_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opération assez couteuse sur toutes les données !\n",
    "# A faire dans une boite séparée\n",
    "\n",
    "index = np.random.permutation(len(Yu))\n",
    "Xm = Xu[index]\n",
    "Ym = Yu[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention: l'exécution peut prendre du temps !\n"
     ]
    }
   ],
   "source": [
    "# validation croisée en multi-classes\n",
    "\n",
    "dim = Xm.shape[1]   # la dimension est donnée par le nombre de colonnes de Xm\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "niter = 10   # nombre d'itérations\n",
    "perf_T = []  # accuracies sur la base d'apprentissage\n",
    "perf_A = []  # accuracies sur la base de test\n",
    "\n",
    "##################### \n",
    "\n",
    "percep_biais = classif.ClassifierPerceptronBiais(dim,eps,poids_0)\n",
    "\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(Xm, Ym, nb_iter, i)\n",
    "    multi = classif.ClassifierMultiOAA(percep_biais)\n",
    "    multi.train(Xapp,Yapp)\n",
    "    perf_T.append(multi.accuracy(Xapp,Yapp))\n",
    "    perf_A.append(multi.accuracy(Xtest,Ytest))\n",
    "    print(\"Itération \",i,\" : taille base app= \",Xapp.shape[0],\" taille base test= \",Xtest.shape[0])\n",
    "    \n",
    "\n",
    "##################### \n",
    "print(\"\\nPerformance A (apprentissage): \",perf_A)\n",
    "print(\"\\nPerferformance T (test) : \",perf_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toujours plus loin...\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Comparer à nouveau les performances de vos classifieurs sur le jeu de données USPS, par une validation croisée en 10 groupes, mais cette fois-ci en traitant le problème comme un problème multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
