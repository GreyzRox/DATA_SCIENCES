{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2024-2025\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME 6 : Apprentissage pour le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\"><b>[Q]</b></font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double-cliquer ici et insérer les noms et prénoms de votre binôme*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> **Renommer ce notebook**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-06</tt> et rajouter à la suite de <tt>tme-06</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-06-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font>.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version python et des librairies:\n",
      "\tPython  3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0]\n",
      "\tpandas:  2.2.3\n",
      "\tnumpy:  2.2.3\n",
      "\tmatplotlib:  3.10.1\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - - - -\n",
    "# imports utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mtpl\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Les instructions suivantes sont utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - -\n",
    "# Information sur l'environnent utilisé ici:\n",
    "print(\"Version python et des librairies:\")\n",
    "print(\"\\tPython \",sys.version)\n",
    "print(\"\\tpandas: \",pd.__version__)\n",
    "print(\"\\tnumpy: \",np.__version__)\n",
    "print(\"\\tmatplotlib: \",mtpl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# importation de evaluation\n",
    "from iads import evaluation as ev\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectifs de ce TME\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Ce TME a pour but d'implémenter des fonctions pour traiter un corpus textuel et un nouvel algorithme d'apprentissage vu dans le cours 6. \n",
    "\n",
    "Pour expérimenter, on utilise la base `SMS spam Collection` qui contient 5572 messages associés à 2 labels: `spam` et `ham`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point  crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf  he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity  * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point  crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf  he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity  * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du dataset\n",
    "\n",
    "df_spam = pd.read_csv('data/spam.csv', sep='\\t', encoding = 'latin1')\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs du label:\n",
    "df_spam['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met les labels dans une liste car cela sera utile:\n",
    "les_labels = df_spam['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> En utilisant `value_counts` (voir la doc de la librairie pandas), afficher le nombre d'exemples de chaque classe dans la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir travailler sur les messages, on commence par les nettoyer : il faut enlever les caractères de ponctuations, les articles, les mots trop courants, etc. (voir le cours 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour traiter les données textuelles (colonne `message` du dataset), on utilise les fonctions de la librairie `string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractères de ponctuations :  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "Mise en minuscules (pour homogénéiser l'écriture :  may the force be with you!\n",
      "Découper une phrase avec espace (retourne une liste): ['LU3IN026', 'est', \"l'UE\", \"d'IA\", 'et', 'Sciences', 'des', 'données.']\n",
      "Découper une phrase avec apostrophe (retourne une liste): ['LU3IN026 est l', 'UE d', 'IA et Sciences des données.']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "print(\"Caractères de ponctuations : \", string.punctuation)\n",
    "\n",
    "print(\"Mise en minuscules (pour homogénéiser l'écriture : \", \"May the Force be with you!\".lower())\n",
    "\n",
    "print(\"Découper une phrase avec espace (retourne une liste):\", \"LU3IN026 est l'UE d'IA et Sciences des données.\".split())\n",
    "\n",
    "print(\"Découper une phrase avec apostrophe (retourne une liste):\", \"LU3IN026 est l'UE d'IA et Sciences des données.\".split(\"'\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec le dataframe du dataset:\n",
    "print(\"Premier message du train: \",df_spam['message'].iloc[0])\n",
    "\n",
    "print(\"Résultat d'un découpage: \",df_spam['message'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certains éléments d'une phrase ne sont pas utiles pour le traitement, par exemple en anglais:\n",
    "mots_inutiles = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `nettoyage` qui prend une chaîne de caractères et rend la chaîne après nettoyage: 1) mise en minuscules 2) remplacement des caractères de ponctuation par un espace (SAUF l'apostrophe qui doit rester car elle va être utilisée pour les mots inutiles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lu3in026 est l'ue d'ia et sciences des données \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage(\"LU3IN026 est l'UE d'IA et Sciences des données.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettoyage(df_spam['message'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `text2vect` qui prend une chaîne de caractères ainsi qu'une liste de mots inutiles et rend la liste composée par les mots de cette chaîne obtenus, après son nettoyage et après avoir enlevé les mots inutiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vect(\"May the Force be with you!\",mots_inutiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vect(\"You shan't pass!\",mots_inutiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2vect(df_spam['message'].iloc[0],mots_inutiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ajouter une nouvelle colonne de nom `les_mots` au dataframe `df_spam` pour laquelle chaque ligne contient le résultat de l'application de `text2vect` sur le message de l'exemple correspondant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>les_mots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point  crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf  he lives aro...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, å£750, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>[ì, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity  * was in mood for that. So...any other s...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>[guy, bitching, acted, like, i'd, interested, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "0      ham  Go until jurong point  crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf  he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
       "5569   ham  Pity  * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                               les_mots  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, goes, usf, lives, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [2nd, time, tried, 2, contact, u, u, å£750, po...  \n",
       "5568                 [ì, b, going, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitching, acted, like, i'd, interested, ...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A COMPLETER \n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage du dataset en 2 ensembles train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Pour mettre au point nos fonctions dans ce TME, on va travailler sur une partie du dataset, par exemple, on peut prendre 5% des exemples (en respectant la distribution des classes, donc en prenant 5% d'exemples de chaque label).\n",
    "Compléter le code ci-dessous pour définir les 2 variables `df_train` et `df_test` qui contiendront chacune 1 dataframe, partie de `df_spam`. Pour construire `df_train` on prend aléatoirement 5% des exemples de chaque classe, comme on l'a déjà fait dans un TME précédent (cf. `np.random.shuffle`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples du label ham pris pour apprendre: 241\n",
      "Nombre d'exemples du label spam pris pour apprendre: 37\n",
      "Dimension de df_train:\t(278, 3)\n",
      "Dimension de df_test:\t(5294, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# pourcentage d'exemples de chaque classe à garder:\n",
    "taux = 0.05    # ici on prend 5% \n",
    "\n",
    "# déclaration des variables qui seront initialisées dans la boucle:\n",
    "df_train = None  \n",
    "df_test = None\n",
    "for l in les_labels:\n",
    "    nb_total = df_spam['label'].value_counts()[l]\n",
    "    nb_pris = int(nb_total*taux) \n",
    "    print(f\"Nombre d'exemples du label {l} pris pour apprendre: {nb_pris}\")\n",
    "\n",
    "    les_ids = df_spam[df_spam['label']==l].index.to_list()\n",
    "    np.random.shuffle(les_ids)\n",
    "\n",
    "    # ################################# COMPLETER ICI \n",
    "\n",
    "    \n",
    "    # ###########################################################\n",
    "    \n",
    "# Résultat:\n",
    "print(f\"Dimension de df_train:\\t{df_train.shape}\")\n",
    "print(f\"Dimension de df_test:\\t{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>les_mots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am late so call you tomorrow morning.take ca...</td>\n",
       "      <td>[late, call, tomorrow, morning, take, care, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>ham</td>\n",
       "      <td>U r too much close to my heart. If u go away i...</td>\n",
       "      <td>[u, r, much, close, heart, u, go, away, shatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait  &amp;lt;#&amp;gt;  min..</td>\n",
       "      <td>[wait, lt, gt, min]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you call me plz. Your number shows out of ...</td>\n",
       "      <td>[call, plz, number, shows, coveragd, area, urg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>ham</td>\n",
       "      <td>MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...</td>\n",
       "      <td>[maybe, woke, fucking, 3, problem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>spam</td>\n",
       "      <td>3 FREE TAROT TEXTS! Find out about your love l...</td>\n",
       "      <td>[3, free, tarot, texts, find, love, life, try,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you want a new Video phone? 600 anytime any...</td>\n",
       "      <td>[want, new, video, phone, 600, anytime, networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>[mobile, 10, mths, update, latest, orange, cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>spam</td>\n",
       "      <td>Valentines Day Special! Win over å£1000 in our...</td>\n",
       "      <td>[valentines, day, special, win, å£1000, quiz, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "3714   ham  I am late so call you tomorrow morning.take ca...   \n",
       "1311   ham  U r too much close to my heart. If u go away i...   \n",
       "548    ham                             Wait  &lt;#&gt;  min..   \n",
       "1324   ham  Can you call me plz. Your number shows out of ...   \n",
       "3184   ham  MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...   \n",
       "...    ...                                                ...   \n",
       "1852  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "2582  spam  3 FREE TAROT TEXTS! Find out about your love l...   \n",
       "3418  spam  Do you want a new Video phone? 600 anytime any...   \n",
       "3422  spam  Had your mobile 10 mths? Update to latest Oran...   \n",
       "2426  spam  Valentines Day Special! Win over å£1000 in our...   \n",
       "\n",
       "                                               les_mots  \n",
       "3714  [late, call, tomorrow, morning, take, care, sw...  \n",
       "1311  [u, r, much, close, heart, u, go, away, shatte...  \n",
       "548                                 [wait, lt, gt, min]  \n",
       "1324  [call, plz, number, shows, coveragd, area, urg...  \n",
       "3184                 [maybe, woke, fucking, 3, problem]  \n",
       "...                                                 ...  \n",
       "1852  [2nd, time, tried, 2, contact, u, u, 750, poun...  \n",
       "2582  [3, free, tarot, texts, find, love, life, try,...  \n",
       "3418  [want, new, video, phone, 600, anytime, networ...  \n",
       "3422  [mobile, 10, mths, update, latest, orange, cam...  \n",
       "2426  [valentines, day, special, win, å£1000, quiz, ...  \n",
       "\n",
       "[278 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculs de probabilités\n",
    "\n",
    "À partir d'ici on va travailler sur les données d'apprentissage (`df_train`) pour déterminer les probabilités qui serviront à classer les messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Construire la liste de tous les mots présents dans tous les vecteurs de `df_train`, chaque mots doit n'apparaître qu'une seule fois dans la liste obtenue. Cette liste sera stockée une fois triée dans la variable `index_mots` (et on l'appelle par la suite \"index de mots\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mots = ######## A COMPLETER ######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots trouvés:  1377\n",
      "Les 10 premiers : [\"'\", \"'t\", '0', '00', '01223585334', '0207', '03', '07801543489', '0800', '08000930705']\n",
      "\ten position  30  -->  10p\n",
      "\ten position  130  -->  al\n",
      "\ten position  230  -->  brain\n",
      "\ten position  330  -->  considering\n",
      "\ten position  430  -->  emerging\n",
      "\ten position  530  -->  go\n",
      "\ten position  630  -->  interesting\n",
      "\ten position  730  -->  lucky\n",
      "\ten position  830  -->  next\n",
      "\ten position  930  -->  porn\n",
      "\ten position  1030  -->  screaming\n",
      "\ten position  1130  -->  sub\n",
      "\ten position  1230  -->  tv\n",
      "\ten position  1330  -->  workin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Nombre de mots trouvés: \", len(index_mots))\n",
    "print(\"Les 10 premiers :\", index_mots[0:10]) \n",
    "\n",
    "# pour contrôler:\n",
    "for i in range(30,len(index_mots),100):\n",
    "    print(\"\\ten position \",i,\" --> \", index_mots[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque message va maintenant être représenté comme un vecteur de valeurs 0 ou 1: ce vecteur possède autant de colonnes qu'il y a de mots dans `index_mots`. Ce vecteur est construit ainsi: pour un exemple $i$, la valeur de la colonne $j$ du vecteur vaudra 1 si la liste de mots de l'exemple $i$ contient le mot en position $j$ dans `index_mots`, ou 0 dans le cas contraire.\n",
    "\n",
    "*Remarque:* même si un mot apparaît plusieurs fois dans la liste, cela ne compte que pour 1.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `df2array` qui prend un dataframe `df` contenant la colonne `les_mots` ainsi qu'un index de mots et rend le `np.array` correspondant aux vecteurs de valeurs représentant les exemples de `df`. Les mots de `les_mots` qui ne sont pas dans l'index de mots ne sont pas pris en compte.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_train = df2array(df_train,index_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 1377)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 0: ['late', 'call', 'tomorrow', 'morning', 'take', 'care', 'sweet', 'dreams', 'u', 'ummifying', 'bye']\n",
      "\n",
      "Positions non nulles dans le vecteur d'index:\n",
      "\tcolonne  245  :  bye\n",
      "\tcolonne  248  :  call\n",
      "\tcolonne  265  :  care\n",
      "\tcolonne  412  :  dreams\n",
      "\tcolonne  679  :  late\n",
      "\tcolonne  791  :  morning\n",
      "\tcolonne  1150  :  sweet\n",
      "\tcolonne  1154  :  take\n",
      "\tcolonne  1209  :  tomorrow\n",
      "\tcolonne  1238  :  u\n",
      "\tcolonne  1244  :  ummifying\n"
     ]
    }
   ],
   "source": [
    "print(\"Message 0:\", df_train['les_mots'].iloc[0])\n",
    "\n",
    "print(\"\\nPositions non nulles dans le vecteur d'index:\")\n",
    "\n",
    "for i in range(0, len(mat_train[0])):\n",
    "    if mat_train[0][i] == 1:\n",
    "        print(\"\\tcolonne \",i,\" : \", index_mots[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on se rappelle qu'il est possible d'extraire les vecteurs correspondant à un label donné, par exemple:\n",
    "len(mat_train[df_train['label']=='ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Construire un dictionnaire qui donne, pour chaque label $l$, pour chaque mot $m$ de l'index des mots, la fréquence de $m$ parmi les exemples de `df_train` qui ont le label $l$.\n",
    "\n",
    "\n",
    "*Remarque*: penser à une solution dans boucle for sur les exemples...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequences = dict()\n",
    "for l in les_labels:\n",
    "    frequences[l] = ############ COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seuls les 10 premiers non nuls sont affichés.\n",
      "Pour le label ham :\n",
      "\t ':\t 0.003597\n",
      "\t 't:\t 0.003597\n",
      "\t 1:\t 0.014388\n",
      "\t 100:\t 0.003597\n",
      "\t 1st:\t 0.003597\n",
      "\t 2:\t 0.050360\n",
      "\t 2marrow:\t 0.003597\n",
      "\t 2nd:\t 0.003597\n",
      "\t 3:\t 0.017986\n",
      "\t 30:\t 0.003597\n",
      "Pour le label spam :\n",
      "\t 0:\t 0.003597\n",
      "\t 00:\t 0.007194\n",
      "\t 01223585334:\t 0.003597\n",
      "\t 0207:\t 0.003597\n",
      "\t 03:\t 0.003597\n",
      "\t 07801543489:\t 0.003597\n",
      "\t 0800:\t 0.003597\n",
      "\t 08000930705:\t 0.007194\n",
      "\t 08000938767:\t 0.003597\n",
      "\t 08002888812:\t 0.003597\n"
     ]
    }
   ],
   "source": [
    "# Affichage de quelques valeurs de fréquence non nulles \n",
    "print(\"Seuls les 10 premiers non nuls sont affichés.\")        \n",
    "for l in frequences:\n",
    "    nb= 0\n",
    "    print(\"Pour le label\",l, \":\")\n",
    "    for j in range(0,len(frequences[l])):\n",
    "        if frequences[l][j] != 0:\n",
    "            if (nb < 10):\n",
    "                print(f'\\t {index_mots[j]}:\\t {frequences[l][j]:0.6f}')\n",
    "            nb +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequences max:\n",
      "\tpour ham: 0.1618705035971223 pour le mot u\n",
      "\tpour spam: 0.06474820143884892 pour le mot call\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequences max:\")\n",
    "print(\"\\tpour ham:\", max(frequences['ham']), \"pour le mot\",index_mots[np.argmax(frequences['ham'])])\n",
    "print(\"\\tpour spam:\", max(frequences['spam']), \"pour le mot\",index_mots[np.argmax(frequences['spam'])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification de textes\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "On considère deux variables $X$ et $Y$ :\n",
    "    <ul>\n",
    "        <li>$X$ est un message</li>\n",
    "        <li>$Y$ est le label d'un message et peut prendre 2 valeurs : <code>'ham'</code> et <code>'spam'</code></li>\n",
    "    </ul>\n",
    "\n",
    "Avec les fonctions précédentes on peut représenter les messages d'un corpus de documents sous la forme d'un vecteur $X \\in \\{0, 1\\}^p$ où $p$ est le nombre total de mots de l'index. Le $i$ème message est représenté par le vecteur ${\\bf x}_i = [x_{i1} \\dots x_{ip}]$, où $x_{ij}$ vaut 1 si le $j$ème mot de l'index est présent dans le message $i$, et 0 sinon.\n",
    "    \n",
    "Comme vu en cours, pour un classifieur bayésien, nous devons estimer, à partir de la base <code>df_train</code>, les probabilités $p(ham)$, $p(spam)$, $p(X |ham)$ et $p(X | spam)$.\n",
    "\n",
    "Les 2 premières sont simples à calculer : on compte le nombre de fois où le label apparaît parmi les exemples.\n",
    "\n",
    "Pour un label $Y$ et un exemple ${\\bf x}$, le calcul de $p({\\bf x} | Y)$ se fait en utilisant les probabilités $p(mot | Y)$ de tous les mots qui composent ${\\bf x}$ (et qui sont des mots de l'index des mots). $p(mot | Y)$ est la probabilité que le mot <code>mot</code> apparaisse dans un message sachant que ce message appartient à la classe $Y$.\n",
    "    \n",
    "On pose ainsi\n",
    "\n",
    "$$ p({\\bf x} | Y) = \\prod_{mot \\in index\\_mots} p(mot | Y)^{x_{mot}} \\left(1 - p(mot | Y)\\right)^{1 - x_{mot}} $$\n",
    "\n",
    "où $x_{mot}$ correspond à $1$ ou $0$ selon que le `mot` apparaît dans ${\\bf x}$ ou pas. Ce terme permet de retenir soit la probabilité $p(mot | Y)$ si le mot est dans ${\\bf x}$, soit la probabilité qu'il n'y soit pas ($1-p(mot |Y)$).\n",
    "    \n",
    "Une fois que $p({\\bf x} | Y)$ est calculée, on peut estimer $p(Y|X)$ grâce au théorème de Bayes (cf. cours 6):\n",
    "\n",
    "$$p(Y|{\\bf x}) = p(Y) p({\\bf x} | Y)$$\n",
    "\n",
    "avec $Y$ qui vaut soit 'ham', soit 'spam'.    \n",
    "\n",
    "    \n",
    "Une fois $p(Y{{\\bf x}})$ calculée pour chaque valeur de label, pour prédire le label de ${\\bf x}$ on choisit le label qui possède la plus forte probabilité.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(ham ) = 0.8669\n",
      "p(spam) = 0.1331\n"
     ]
    }
   ],
   "source": [
    "for l in ['ham', 'spam']:\n",
    "    # #################### A COMPLETER \n",
    "    proba = ##### COMPLETER\n",
    "    ##########################\n",
    "    print(f'p({l:4}) = {proba:0.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `proba_mot` qui étant donné un mot, un label, une liste de mots, et un dictionnaire avec les fréquences des mots par label (comme `frequences` et compatible avec la liste de mots) rend $p(mot| label)$ la probabilité du mot d'appartenir au label donné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot qui n'est pas dans l'index:\n",
    "proba_mot(\"toto\", \"ham\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot de l'index pour un label qui n'existe pas:\n",
    "proba_mot(\"visit\", \"cookie\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046762589928057555"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot de l'index pour un label qui existe:\n",
    "proba_mot(\"call\", \"ham\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06474820143884892"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot de l'index pour un label qui existe:\n",
    "proba_mot(\"call\", \"spam\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `proba_exemple` qui étant donné un exemple représenté sous la forme d'une liste de mots, un label, une liste de mots, et un dictionnaire comme `frequences` (compatible avec la liste de mots) rend $p(exemple|label)$ la probabilité de l'exemple d'appartenir au label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1316038568344261e-16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_exemple(df_train['les_mots'].iloc[10], 'ham', index_mots,frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 155 : p(ham)= 0.0010052408719834576 \tp(spam)= 0.08832069248325923\n",
      "Exemple 230 : p(ham)= 1.1730192868566778e-09 \tp(spam)= 6.795189200970217e-08\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df_train)):\n",
    "    p_spam = proba_exemple(df_train['les_mots'].iloc[i], 'spam', index_mots,frequences)\n",
    "    p_ham = proba_exemple(df_train['les_mots'].iloc[i], 'ham', index_mots,frequences)\n",
    "    if (p_spam>0) and (p_ham>0):\n",
    "        print(\"Exemple\",i,\": p(ham)=\",p_ham,\"\\tp(spam)=\",p_spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> À partir de `mat_train` et de `frequences` et en utilisant des opérations matricielles, on peut aussi calculer les probabilités pour chaque label de tous les exemples. En terme de temps de calcul, cela peut être plus efficace.\n",
    "\n",
    "Donner l'instruction permettant de calculer toutes ces probabilités, puis vérifier que vous trouver les mêmes valeurs pour les exemples précédents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toutes_probas = dict()\n",
    "for l in les_labels:\n",
    "    toutes_probas[l] = ############ COMPLETER ICI ##########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 155 : p(ham)= 0.0010052408719834576 \tp(spam)= 0.08832069248325923\n",
      "Exemple 230 : p(ham)= 1.1730192868566778e-09 \tp(spam)= 6.795189200970217e-08\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df_train)):\n",
    "    p_spam = toutes_probas['spam'][i]\n",
    "    p_ham = toutes_probas['ham'][i]\n",
    "    if (p_spam>0) and (p_ham>0):\n",
    "        print(\"Exemple\",i,\": p(ham)=\",p_ham,\"\\tp(spam)=\",p_spam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> En utilisant les fonctions écrites, calculer le taux de bonne prédiction du classifieur bayésien naïf pour chaque valeur de label pour le dataset d'apprentissage. \n",
    "\n",
    "*Remarque*: une solution efficace peut ne pas utiliser toutes les fonctions précédentes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats des classements :  {'ham': {True: 239, False: 2}, 'spam': {True: 37, False: 0}}\n",
      "Temps:  0.03742384910583496\n"
     ]
    }
   ],
   "source": [
    "# La variable suivante permettra de stocker les résultats\n",
    "taux = dict()\n",
    "toutes_probas = dict()\n",
    "for l in les_labels:\n",
    "    taux[l] = dict()\n",
    "    taux[l][True] = 0    # nombre de bien classés\n",
    "    taux[l][False] = 0   # nombre de mal classés\n",
    "    toutes_probas[l] = np.zeros(1)\n",
    "tic = time.time()\n",
    "\n",
    "# ################################## A COMPLETER\n",
    "\n",
    "\n",
    "# #############################################\n",
    "toc = time.time()\n",
    "print(\"Résultats des classements : \", taux)\n",
    "\n",
    "print(\"Temps: \",toc-tic)\n",
    "# le résultat total peut prendre un certain temps...\n",
    "\n",
    "\n",
    "# Il reste à calculer les taux de bonne classification par label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Même question pour calculer le taux de bonne classification pour le dataset de test.\n",
    "\n",
    "*Remarque*: L'index des mots ainsi que la matrice des fréquences restent les mêmes, ce sont toujours celles construites à partir de la base d'apprentissage. Par contre, la matrice des présences doit, elle, être recalculées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats des classements :  {'ham': {True: 4256, False: 328}, 'spam': {True: 206, False: 504}}\n",
      "Temps:  0.4609973430633545\n"
     ]
    }
   ],
   "source": [
    "# La variable suivante permettra de stocker les résultats\n",
    "taux = dict()\n",
    "toutes_probas = dict()\n",
    "for l in les_labels:\n",
    "    taux[l] = dict()\n",
    "    taux[l][True] = 0    # nombre de bien classés\n",
    "    taux[l][False] = 0   # nombre de mal classés\n",
    "    toutes_probas[l] = np.zeros(1)\n",
    "tic = time.time()\n",
    "\n",
    "# ################################## A COMPLETER\n",
    "\n",
    "\n",
    "# #############################################\n",
    "toc = time.time()\n",
    "print(\"Résultats des classements : \", taux)\n",
    "\n",
    "print(\"Temps: \",toc-tic)\n",
    "# le résultat total peut prendre un certain temps...\n",
    "\n",
    "\n",
    "# Il reste à calculer les taux de bonne classification par label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du classifieur Naive Bayes\n",
    "\n",
    "Pour tout ce que l'on a fait jusque-là, on a travaillé sur tout le dataset, pour pouvoir l'évaluer il est nécessaire de le séparer en ensemble d'apprentissage et ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Découper aléatoirement `df_spam` en 2 parties égales, chacune contenant des exemples des 2 labels, avec la même distribution des labels dans chaque partie. \n",
    "Une des parties sert à apprendre l'index des mots et leurs fréquences.\n",
    "L'autre partie n'est utilisée que pour calculer le taux de bonne classification par label.\n",
    "\n",
    "Donner ensuite les taux de bonne classification par label pour l'ensemble de train et pour l'ensemble de test.\n",
    "\n",
    "*Remarque*: certains mots de la partie de test pourront ne pas être présents dans l'index de mots car ils peuvent être absents de la partie d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Mettre en place une approche par validation croisée pour évaluer le taux de bonne classification moyen de cette approche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Comparer les résultats obtenus (taux de bonne classification avec la validation croisée, temps de calcul) avec ceux obtenus avec l'application d'un classifieur par $k$ plus proches voisins. Pour cela, la `mat_spam` doit être utilisée comme description des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
