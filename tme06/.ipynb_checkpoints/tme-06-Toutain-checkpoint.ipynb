{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "IA & Data science (LU3IN0226) -- 2024-2025\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME 6 : Apprentissage pour le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\"><b>[Q]</b></font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOUTAIN Yanis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> **Renommer ce notebook**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-06</tt> et rajouter à la suite de <tt>tme-06</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-06-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font>.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Version python et des librairies:\n",
      "\tPython  3.11.2 (main, Nov 30 2024, 21:22:50) [GCC 12.2.0]\n",
      "\tpandas:  2.2.0\n",
      "\tnumpy:  1.24.2\n",
      "\tmatplotlib:  3.6.3\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - - - -\n",
    "# imports utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mtpl\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Les instructions suivantes sont utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - -\n",
    "# Information sur l'environnent utilisé ici:\n",
    "print(\"Version python et des librairies:\")\n",
    "print(\"\\tPython \",sys.version)\n",
    "print(\"\\tpandas: \",pd.__version__)\n",
    "print(\"\\tnumpy: \",np.__version__)\n",
    "print(\"\\tmatplotlib: \",mtpl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# importation de evaluation\n",
    "from iads import evaluation as ev\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectifs de ce TME\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Ce TME a pour but d'implémenter des fonctions pour traiter un corpus textuel et un nouvel algorithme d'apprentissage vu dans le cours 6. \n",
    "\n",
    "Pour expérimenter, on utilise la base `SMS spam Collection` qui contient 5572 messages associés à 2 labels: `spam` et `ham`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point  crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf  he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity  * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point  crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf  he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity  * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du dataset\n",
    "\n",
    "df_spam = pd.read_csv('data/spam.csv', sep='\\t', encoding = 'latin1')\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs du label:\n",
    "df_spam['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met les labels dans une liste car cela sera utile:\n",
    "les_labels = df_spam['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> En utilisant `value_counts` (voir la doc de la librairie pandas), afficher le nombre d'exemples de chaque classe dans la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir travailler sur les messages, on commence par les nettoyer : il faut enlever les caractères de ponctuations, les articles, les mots trop courants, etc. (voir le cours 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour traiter les données textuelles (colonne `message` du dataset), on utilise les fonctions de la librairie `string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractères de ponctuations :  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "Mise en minuscules (pour homogénéiser l'écriture :  may the force be with you!\n",
      "Découper une phrase avec espace (retourne une liste): ['LU3IN026', 'est', \"l'UE\", \"d'IA\", 'et', 'Sciences', 'des', 'données.']\n",
      "Découper une phrase avec apostrophe (retourne une liste): ['LU3IN026 est l', 'UE d', 'IA et Sciences des données.']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "print(\"Caractères de ponctuations : \", string.punctuation)\n",
    "\n",
    "print(\"Mise en minuscules (pour homogénéiser l'écriture : \", \"May the Force be with you!\".lower())\n",
    "\n",
    "print(\"Découper une phrase avec espace (retourne une liste):\", \"LU3IN026 est l'UE d'IA et Sciences des données.\".split())\n",
    "\n",
    "print(\"Découper une phrase avec apostrophe (retourne une liste):\", \"LU3IN026 est l'UE d'IA et Sciences des données.\".split(\"'\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier message du train:  Go until jurong point  crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Résultat d'un découpage:  ['Go', 'until', 'jurong', 'point', 'crazy..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'Cine', 'there', 'got', 'amore', 'wat...']\n"
     ]
    }
   ],
   "source": [
    "# Avec le dataframe du dataset:\n",
    "print(\"Premier message du train: \",df_spam['message'].iloc[0])\n",
    "\n",
    "print(\"Résultat d'un découpage: \",df_spam['message'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certains éléments d'une phrase ne sont pas utiles pour le traitement, par exemple en anglais:\n",
    "mots_inutiles = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `nettoyage` qui prend une chaîne de caractères et rend la chaîne après nettoyage: 1) mise en minuscules 2) remplacement des caractères de ponctuation par un espace (SAUF l'apostrophe qui doit rester car elle va être utilisée pour les mots inutiles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyage(chaine):\n",
    "\n",
    "    res = chaine.lower()\n",
    "    for car in string.punctuation:\n",
    "        if(car != \"'\" and car in chaine):\n",
    "            res=res.replace(car,' ')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lu3in026 est l'ue d'ia et sciences des données \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage(\"LU3IN026 est l'UE d'IA et Sciences des données.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point  crazy   available only in bugis n great world la e buffet    cine there got amore wat   '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage(df_spam['message'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `text2vect` qui prend une chaîne de caractères ainsi qu'une liste de mots inutiles et rend la liste composée par les mots de cette chaîne obtenus, après son nettoyage et après avoir enlevé les mots inutiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vect(chaine,mots_inutiles):\n",
    "    chaine_nettoye = nettoyage(chaine)\n",
    "    res = chaine_nettoye.split()\n",
    "    return [mot for mot in res if mot not in mots_inutiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['may', 'force']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vect(\"May the Force be with you!\",mots_inutiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pass']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vect(\"You shan't pass!\",mots_inutiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2vect(df_spam['message'].iloc[0],mots_inutiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ajouter une nouvelle colonne de nom `les_mots` au dataframe `df_spam` pour laquelle chaque ligne contient le résultat de l'application de `text2vect` sur le message de l'exemple correspondant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>les_mots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point  crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf  he lives aro...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, å£750, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>[ì, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity  * was in mood for that. So...any other s...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>[guy, bitching, acted, like, i'd, interested, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "0      ham  Go until jurong point  crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf  he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
       "5569   ham  Pity  * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                               les_mots  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, goes, usf, lives, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [2nd, time, tried, 2, contact, u, u, å£750, po...  \n",
       "5568                 [ì, b, going, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitching, acted, like, i'd, interested, ...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A COMPLETER \n",
    "df_spam[\"les_mots\"] = df_spam[\"message\"].apply(text2vect, args=(mots_inutiles,))\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage du dataset en 2 ensembles train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Pour mettre au point nos fonctions dans ce TME, on va travailler sur une partie du dataset, par exemple, on peut prendre 5% des exemples (en respectant la distribution des classes, donc en prenant 5% d'exemples de chaque label).\n",
    "Compléter le code ci-dessous pour définir les 2 variables `df_train` et `df_test` qui contiendront chacune 1 dataframe, partie de `df_spam`. Pour construire `df_train` on prend aléatoirement 5% des exemples de chaque classe, comme on l'a déjà fait dans un TME précédent (cf. `np.random.shuffle`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples du label ham pris pour apprendre: 241\n",
      "Nombre d'exemples du label spam pris pour apprendre: 37\n",
      "Dimension de df_train:\t(278, 3)\n",
      "Dimension de df_test:\t(5294, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# pourcentage d'exemples de chaque classe à garder:\n",
    "taux = 0.05    # ici on prend 5% \n",
    "\n",
    "# déclaration des variables qui seront initialisées dans la boucle:\n",
    "df_train = None  \n",
    "df_test = None\n",
    "for l in les_labels:\n",
    "    nb_total = df_spam['label'].value_counts()[l]\n",
    "    nb_pris = int(nb_total*taux) \n",
    "    print(f\"Nombre d'exemples du label {l} pris pour apprendre: {nb_pris}\")\n",
    "\n",
    "    les_ids = df_spam[df_spam['label']==l].index.to_list()\n",
    "    np.random.shuffle(les_ids)\n",
    "\n",
    "    selected_ids = les_ids[:nb_pris]\n",
    "    cpt = df_spam.iloc[selected_ids]\n",
    "    df_train = pd.concat([df_train,cpt])\n",
    "\n",
    "df_test = df_spam[~df_spam.index.isin(df_train.index)]\n",
    "    # ###########################################################\n",
    "    \n",
    "# Résultat:\n",
    "print(f\"Dimension de df_train:\\t{df_train.shape}\")\n",
    "print(f\"Dimension de df_test:\\t{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>les_mots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am late so call you tomorrow morning.take ca...</td>\n",
       "      <td>[late, call, tomorrow, morning, take, care, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>ham</td>\n",
       "      <td>U r too much close to my heart. If u go away i...</td>\n",
       "      <td>[u, r, much, close, heart, u, go, away, shatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait  &amp;lt;#&amp;gt;  min..</td>\n",
       "      <td>[wait, lt, gt, min]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you call me plz. Your number shows out of ...</td>\n",
       "      <td>[call, plz, number, shows, coveragd, area, urg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>ham</td>\n",
       "      <td>MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...</td>\n",
       "      <td>[maybe, woke, fucking, 3, problem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>spam</td>\n",
       "      <td>3 FREE TAROT TEXTS! Find out about your love l...</td>\n",
       "      <td>[3, free, tarot, texts, find, love, life, try,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you want a new Video phone? 600 anytime any...</td>\n",
       "      <td>[want, new, video, phone, 600, anytime, networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>[mobile, 10, mths, update, latest, orange, cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>spam</td>\n",
       "      <td>Valentines Day Special! Win over å£1000 in our...</td>\n",
       "      <td>[valentines, day, special, win, å£1000, quiz, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "3714   ham  I am late so call you tomorrow morning.take ca...   \n",
       "1311   ham  U r too much close to my heart. If u go away i...   \n",
       "548    ham                             Wait  &lt;#&gt;  min..   \n",
       "1324   ham  Can you call me plz. Your number shows out of ...   \n",
       "3184   ham  MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...   \n",
       "...    ...                                                ...   \n",
       "1852  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "2582  spam  3 FREE TAROT TEXTS! Find out about your love l...   \n",
       "3418  spam  Do you want a new Video phone? 600 anytime any...   \n",
       "3422  spam  Had your mobile 10 mths? Update to latest Oran...   \n",
       "2426  spam  Valentines Day Special! Win over å£1000 in our...   \n",
       "\n",
       "                                               les_mots  \n",
       "3714  [late, call, tomorrow, morning, take, care, sw...  \n",
       "1311  [u, r, much, close, heart, u, go, away, shatte...  \n",
       "548                                 [wait, lt, gt, min]  \n",
       "1324  [call, plz, number, shows, coveragd, area, urg...  \n",
       "3184                 [maybe, woke, fucking, 3, problem]  \n",
       "...                                                 ...  \n",
       "1852  [2nd, time, tried, 2, contact, u, u, 750, poun...  \n",
       "2582  [3, free, tarot, texts, find, love, life, try,...  \n",
       "3418  [want, new, video, phone, 600, anytime, networ...  \n",
       "3422  [mobile, 10, mths, update, latest, orange, cam...  \n",
       "2426  [valentines, day, special, win, å£1000, quiz, ...  \n",
       "\n",
       "[278 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculs de probabilités\n",
    "\n",
    "À partir d'ici on va travailler sur les données d'apprentissage (`df_train`) pour déterminer les probabilités qui serviront à classer les messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Construire la liste de tous les mots présents dans tous les vecteurs de `df_train`, chaque mots doit n'apparaître qu'une seule fois dans la liste obtenue. Cette liste sera stockée une fois triée dans la variable `index_mots` (et on l'appelle par la suite \"index de mots\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mots = np.unique([mot for sous_liste in df_train[\"les_mots\"] for mot in sous_liste])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots trouvés:  1377\n",
      "Les 10 premiers : [\"'\" \"'t\" '0' '00' '01223585334' '0207' '03' '07801543489' '0800'\n",
      " '08000930705']\n",
      "\ten position  30  -->  10p\n",
      "\ten position  130  -->  al\n",
      "\ten position  230  -->  brain\n",
      "\ten position  330  -->  considering\n",
      "\ten position  430  -->  emerging\n",
      "\ten position  530  -->  go\n",
      "\ten position  630  -->  interesting\n",
      "\ten position  730  -->  lucky\n",
      "\ten position  830  -->  next\n",
      "\ten position  930  -->  porn\n",
      "\ten position  1030  -->  screaming\n",
      "\ten position  1130  -->  sub\n",
      "\ten position  1230  -->  tv\n",
      "\ten position  1330  -->  workin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Nombre de mots trouvés: \", len(index_mots))\n",
    "print(\"Les 10 premiers :\", index_mots[0:10]) \n",
    "\n",
    "# pour contrôler:\n",
    "for i in range(30,len(index_mots),100):\n",
    "    print(\"\\ten position \",i,\" --> \", index_mots[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque message va maintenant être représenté comme un vecteur de valeurs 0 ou 1: ce vecteur possède autant de colonnes qu'il y a de mots dans `index_mots`. Ce vecteur est construit ainsi: pour un exemple $i$, la valeur de la colonne $j$ du vecteur vaudra 1 si la liste de mots de l'exemple $i$ contient le mot en position $j$ dans `index_mots`, ou 0 dans le cas contraire.\n",
    "\n",
    "*Remarque:* même si un mot apparaît plusieurs fois dans la liste, cela ne compte que pour 1.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `df2array` qui prend un dataframe `df` contenant la colonne `les_mots` ainsi qu'un index de mots et rend le `np.array` correspondant aux vecteurs de valeurs représentant les exemples de `df`. Les mots de `les_mots` qui ne sont pas dans l'index de mots ne sont pas pris en compte.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2array(df,index_mots):\n",
    "    mot_to_index = {mot: i for i, mot in enumerate(index_mots)}\n",
    "    res = []\n",
    "\n",
    "    for mots in df[\"les_mots\"]:\n",
    "        v = np.zeros(len(index_mots), dtype = int)\n",
    "        for mot in mots:\n",
    "            if mot in mot_to_index:\n",
    "                v[mot_to_index[mot]] = 1\n",
    "\n",
    "        res.append(v)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_train = df2array(df_train,index_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 1377)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 0: ['late', 'call', 'tomorrow', 'morning', 'take', 'care', 'sweet', 'dreams', 'u', 'ummifying', 'bye']\n",
      "\n",
      "Positions non nulles dans le vecteur d'index:\n",
      "\tcolonne  245  :  bye\n",
      "\tcolonne  248  :  call\n",
      "\tcolonne  265  :  care\n",
      "\tcolonne  412  :  dreams\n",
      "\tcolonne  679  :  late\n",
      "\tcolonne  791  :  morning\n",
      "\tcolonne  1150  :  sweet\n",
      "\tcolonne  1154  :  take\n",
      "\tcolonne  1209  :  tomorrow\n",
      "\tcolonne  1238  :  u\n",
      "\tcolonne  1244  :  ummifying\n"
     ]
    }
   ],
   "source": [
    "print(\"Message 0:\", df_train['les_mots'].iloc[0])\n",
    "\n",
    "print(\"\\nPositions non nulles dans le vecteur d'index:\")\n",
    "\n",
    "for i in range(0, len(mat_train[0])):\n",
    "    if mat_train[0][i] == 1:\n",
    "        print(\"\\tcolonne \",i,\" : \", index_mots[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on se rappelle qu'il est possible d'extraire les vecteurs correspondant à un label donné, par exemple:\n",
    "len(mat_train[df_train['label']=='ham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Construire un dictionnaire qui donne, pour chaque label $l$, pour chaque mot $m$ de l'index des mots, la fréquence de $m$ parmi les exemples de `df_train` qui ont le label $l$.\n",
    "\n",
    "\n",
    "*Remarque*: penser à une solution dans boucle for sur les exemples...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequences = dict()\n",
    "for l in les_labels:\n",
    "    frequences[l] = np.array([0.0] * len(index_mots))\n",
    "\n",
    "    count = mat_train[df_train['label'] == l].sum(axis=0)\n",
    "    size_count = len(mat_train[df_train['label'] == l])\n",
    "    for id_element in range(len(count)):\n",
    "        frequences[l][id_element] = count[id_element] / size_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seuls les 10 premiers non nuls sont affichés.\n",
      "Pour le label ham :\n",
      "\t ':\t 0.004149\n",
      "\t 't:\t 0.004149\n",
      "\t 1:\t 0.016598\n",
      "\t 100:\t 0.004149\n",
      "\t 1st:\t 0.004149\n",
      "\t 2:\t 0.058091\n",
      "\t 2marrow:\t 0.004149\n",
      "\t 2nd:\t 0.004149\n",
      "\t 3:\t 0.020747\n",
      "\t 30:\t 0.004149\n",
      "Pour le label spam :\n",
      "\t 0:\t 0.027027\n",
      "\t 00:\t 0.054054\n",
      "\t 01223585334:\t 0.027027\n",
      "\t 0207:\t 0.027027\n",
      "\t 03:\t 0.027027\n",
      "\t 07801543489:\t 0.027027\n",
      "\t 0800:\t 0.027027\n",
      "\t 08000930705:\t 0.054054\n",
      "\t 08000938767:\t 0.027027\n",
      "\t 08002888812:\t 0.027027\n"
     ]
    }
   ],
   "source": [
    "# Affichage de quelques valeurs de fréquence non nulles \n",
    "print(\"Seuls les 10 premiers non nuls sont affichés.\")        \n",
    "for l in frequences:\n",
    "    nb= 0\n",
    "    print(\"Pour le label\",l, \":\")\n",
    "    for j in range(0,len(frequences[l])):\n",
    "        if frequences[l][j] != 0:\n",
    "            if (nb < 10):\n",
    "                print(f'\\t {index_mots[j]}:\\t {frequences[l][j]:0.6f}')\n",
    "            nb +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequences max:\n",
      "\tpour ham: 0.18672199170124482 pour le mot u\n",
      "\tpour spam: 0.4864864864864865 pour le mot call\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequences max:\")\n",
    "print(\"\\tpour ham:\", max(frequences['ham']), \"pour le mot\",index_mots[np.argmax(frequences['ham'])])\n",
    "print(\"\\tpour spam:\", max(frequences['spam']), \"pour le mot\",index_mots[np.argmax(frequences['spam'])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification de textes\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "On considère deux variables $X$ et $Y$ :\n",
    "    <ul>\n",
    "        <li>$X$ est un message</li>\n",
    "        <li>$Y$ est le label d'un message et peut prendre 2 valeurs : <code>'ham'</code> et <code>'spam'</code></li>\n",
    "    </ul>\n",
    "\n",
    "Avec les fonctions précédentes on peut représenter les messages d'un corpus de documents sous la forme d'un vecteur $X \\in \\{0, 1\\}^p$ où $p$ est le nombre total de mots de l'index. Le $i$ème message est représenté par le vecteur ${\\bf x}_i = [x_{i1} \\dots x_{ip}]$, où $x_{ij}$ vaut 1 si le $j$ème mot de l'index est présent dans le message $i$, et 0 sinon.\n",
    "    \n",
    "Comme vu en cours, pour un classifieur bayésien, nous devons estimer, à partir de la base <code>df_train</code>, les probabilités $p(ham)$, $p(spam)$, $p(X |ham)$ et $p(X | spam)$.\n",
    "\n",
    "Les 2 premières sont simples à calculer : on compte le nombre de fois où le label apparaît parmi les exemples.\n",
    "\n",
    "Pour un label $Y$ et un exemple ${\\bf x}$, le calcul de $p({\\bf x} | Y)$ se fait en utilisant les probabilités $p(mot | Y)$ de tous les mots qui composent ${\\bf x}$ (et qui sont des mots de l'index des mots). $p(mot | Y)$ est la probabilité que le mot <code>mot</code> apparaisse dans un message sachant que ce message appartient à la classe $Y$.\n",
    "    \n",
    "On pose ainsi\n",
    "\n",
    "$$ p({\\bf x} | Y) = \\prod_{mot \\in index\\_mots} p(mot | Y)^{x_{mot}} \\left(1 - p(mot | Y)\\right)^{1 - x_{mot}} $$\n",
    "\n",
    "où $x_{mot}$ correspond à $1$ ou $0$ selon que le `mot` apparaît dans ${\\bf x}$ ou pas. Ce terme permet de retenir soit la probabilité $p(mot | Y)$ si le mot est dans ${\\bf x}$, soit la probabilité qu'il n'y soit pas ($1-p(mot |Y)$).\n",
    "    \n",
    "Une fois que $p({\\bf x} | Y)$ est calculée, on peut estimer $p(Y|X)$ grâce au théorème de Bayes (cf. cours 6):\n",
    "\n",
    "$$p(Y|{\\bf x}) = p(Y) p({\\bf x} | Y)$$\n",
    "\n",
    "avec $Y$ qui vaut soit 'ham', soit 'spam'.    \n",
    "\n",
    "    \n",
    "Une fois $p(Y{{\\bf x}})$ calculée pour chaque valeur de label, pour prédire le label de ${\\bf x}$ on choisit le label qui possède la plus forte probabilité.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(ham ) = 0.8669\n",
      "p(spam) = 0.1331\n"
     ]
    }
   ],
   "source": [
    "for l in ['ham', 'spam']:\n",
    "    # #################### A COMPLETER \n",
    "    proba = len(df_train[df_train[\"label\"] == l])/len(df_train)\n",
    "    ##########################\n",
    "    print(f'p({l:4}) = {proba:0.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `proba_mot` qui étant donné un mot, un label, une liste de mots, et un dictionnaire avec les fréquences des mots par label (comme `frequences` et compatible avec la liste de mots) rend $p(mot| label)$ la probabilité du mot d'appartenir au label donné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_mot(mot,label,index_mots,frequences):\n",
    "    if mot in index_mots and label in frequences:\n",
    "        index = np.where(index_mots == mot)[0][0]\n",
    "        return frequences[label][index]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot qui n'est pas dans l'index:\n",
    "proba_mot(\"toto\", \"ham\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot de l'index pour un label qui n'existe pas:\n",
    "proba_mot(\"visit\", \"cookie\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05394190871369295"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot de l'index pour un label qui existe:\n",
    "proba_mot(\"call\", \"ham\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4864864864864865"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilité d'un mot de l'index pour un label qui existe:\n",
    "proba_mot(\"call\", \"spam\", index_mots, frequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `proba_exemple` qui étant donné un exemple représenté sous la forme d'une liste de mots, un label, une liste de mots, et un dictionnaire comme `frequences` (compatible avec la liste de mots) rend $p(exemple|label)$ la probabilité de l'exemple d'appartenir au label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_exemple(exemple,label,index_mots,frequences):\n",
    "    res = 1\n",
    "    for mot in index_mots:\n",
    "        if mot in exemple:\n",
    "            res=res*proba_mot(mot,label,index_mots,frequences)\n",
    "        else:\n",
    "            res=res*(1-proba_mot(mot,label,index_mots,frequences))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.743474723482465e-16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_exemple(df_train['les_mots'].iloc[10], 'ham', index_mots,frequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 155 : p(ham)= 0.00034444356666484764 \tp(spam)= 5.691806029912198e-09\n",
      "Exemple 230 : p(ham)= 6.211338526794225e-10 \tp(spam)= 2.3229490990356926e-12\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df_train)):\n",
    "    p_spam = proba_exemple(df_train['les_mots'].iloc[i], 'spam', index_mots,frequences)\n",
    "    p_ham = proba_exemple(df_train['les_mots'].iloc[i], 'ham', index_mots,frequences)\n",
    "    if (p_spam>0) and (p_ham>0):\n",
    "        print(\"Exemple\",i,\": p(ham)=\",p_ham,\"\\tp(spam)=\",p_spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> À partir de `mat_train` et de `frequences` et en utilisant des opérations matricielles, on peut aussi calculer les probabilités pour chaque label de tous les exemples. En terme de temps de calcul, cela peut être plus efficace.\n",
    "\n",
    "Donner l'instruction permettant de calculer toutes ces probabilités, puis vérifier que vous trouver les mêmes valeurs pour les exemples précédents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "toutes_probas = dict()\n",
    "for l in les_labels:\n",
    "    \n",
    "    frequences_label = frequences[l]\n",
    "    \n",
    "    # Calculer les scores en effectuant un produit scalaire avec mat_train\n",
    "    probas_label = np.dot(mat_train, frequences_label)\n",
    "    \n",
    "    exp_scores = np.exp(probas_label)\n",
    "    \n",
    "    probas_label_normalized = exp_scores / np.sum(exp_scores, axis=0, keepdims=True)\n",
    "    \n",
    "    # Sauvegarder les probabilités dans le dictionnaire\n",
    "    toutes_probas[l] = probas_label_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 0 : p(ham)= 0.004446708967079718 \tp(spam)= 0.0042965193774574485\n",
      "Exemple 1 : p(ham)= 0.00437351377811864 \tp(spam)= 0.002641425573375015\n",
      "Exemple 2 : p(ham)= 0.0034523398944196187 \tp(spam)= 0.002246012898483751\n",
      "Exemple 3 : p(ham)= 0.0035540858117855344 \tp(spam)= 0.003753430090404869\n",
      "Exemple 4 : p(ham)= 0.003244014375045899 \tp(spam)= 0.002307543701696923\n",
      "Exemple 5 : p(ham)= 0.0034238083228240405 \tp(spam)= 0.002570991788290878\n",
      "Exemple 6 : p(ham)= 0.004994547598983924 \tp(spam)= 0.003191554015975859\n",
      "Exemple 7 : p(ham)= 0.0034955836735742333 \tp(spam)= 0.002307543701696923\n",
      "Exemple 8 : p(ham)= 0.0030992756223870268 \tp(spam)= 0.002246012898483751\n",
      "Exemple 9 : p(ham)= 0.003568863694121789 \tp(spam)= 0.002641425573375015\n",
      "Exemple 10 : p(ham)= 0.003367450621204499 \tp(spam)= 0.002307543701696923\n",
      "Exemple 11 : p(ham)= 0.003244014375045899 \tp(spam)= 0.002246012898483751\n",
      "Exemple 12 : p(ham)= 0.004932760174188331 \tp(spam)= 0.003191554015975859\n",
      "Exemple 13 : p(ham)= 0.003909985084235422 \tp(spam)= 0.004070440374659573\n",
      "Exemple 14 : p(ham)= 0.0033396206098406777 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 15 : p(ham)= 0.004521129151767083 \tp(spam)= 0.0045351551826652734\n",
      "Exemple 16 : p(ham)= 0.003568863694121789 \tp(spam)= 0.002246012898483751\n",
      "Exemple 17 : p(ham)= 0.004213199586755447 \tp(spam)= 0.002788134726348021\n",
      "Exemple 18 : p(ham)= 0.0038456246551643097 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 19 : p(ham)= 0.003086442201331834 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 20 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 21 : p(ham)= 0.003829700766348657 \tp(spam)= 0.002713788932137246\n",
      "Exemple 22 : p(ham)= 0.0030992756223870268 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 23 : p(ham)= 0.003367450621204499 \tp(spam)= 0.002307543701696923\n",
      "Exemple 24 : p(ham)= 0.003177404534930269 \tp(spam)= 0.002307543701696923\n",
      "Exemple 25 : p(ham)= 0.0030992756223870268 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 26 : p(ham)= 0.0036588303422710237 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 27 : p(ham)= 0.004483764661586088 \tp(spam)= 0.0031064510201119873\n",
      "Exemple 28 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 29 : p(ham)= 0.004178379954467712 \tp(spam)= 0.003023617301179902\n",
      "Exemple 30 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.002307543701696923\n",
      "Exemple 31 : p(ham)= 0.0034380445115983244 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 32 : p(ham)= 0.0035540858117855344 \tp(spam)= 0.002307543701696923\n",
      "Exemple 33 : p(ham)= 0.00370466060699702 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 34 : p(ham)= 0.0032172044921174206 \tp(spam)= 0.002307543701696923\n",
      "Exemple 35 : p(ham)= 0.003230581622539686 \tp(spam)= 0.002370760176326591\n",
      "Exemple 36 : p(ham)= 0.0032038827534602425 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 37 : p(ham)= 0.0035393691214210287 \tp(spam)= 0.002570991788290878\n",
      "Exemple 38 : p(ham)= 0.003409631082987193 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 39 : p(ham)= 0.0034380445115983244 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 40 : p(ham)= 0.005404246381545532 \tp(spam)= 0.003023617301179902\n",
      "Exemple 41 : p(ham)= 0.0031380969420289383 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 42 : p(ham)= 0.003244014375045899 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 43 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 44 : p(ham)= 0.0031642475991724758 \tp(spam)= 0.002307543701696923\n",
      "Exemple 45 : p(ham)= 0.0055635180704805 \tp(spam)= 0.0044142249741147\n",
      "Exemple 46 : p(ham)= 0.00370466060699702 \tp(spam)= 0.0038562574465714383\n",
      "Exemple 47 : p(ham)= 0.003177404534930269 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 48 : p(ham)= 0.0031642475991724758 \tp(spam)= 0.002370760176326591\n",
      "Exemple 49 : p(ham)= 0.0031380969420289383 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 50 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 51 : p(ham)= 0.003367450621204499 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 52 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 53 : p(ham)= 0.0033396206098406777 \tp(spam)= 0.002307543701696923\n",
      "Exemple 54 : p(ham)= 0.0031511451434019276 \tp(spam)= 0.002246012898483751\n",
      "Exemple 55 : p(ham)= 0.003353506746257615 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 56 : p(ham)= 0.003112162404783608 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 57 : p(ham)= 0.0030992756223870268 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 58 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.002307543701696923\n",
      "Exemple 59 : p(ham)= 0.003628592247802017 \tp(spam)= 0.002246012898483751\n",
      "Exemple 60 : p(ham)= 0.003367450621204499 \tp(spam)= 0.005479689786532599\n",
      "Exemple 61 : p(ham)= 0.003284648682645691 \tp(spam)= 0.002246012898483751\n",
      "Exemple 62 : p(ham)= 0.0033120205972562403 \tp(spam)= 0.002246012898483751\n",
      "Exemple 63 : p(ham)= 0.0030992756223870268 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 64 : p(ham)= 0.004319409147358295 \tp(spam)= 0.003191554015975859\n",
      "Exemple 65 : p(ham)= 0.0030992756223870268 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 66 : p(ham)= 0.0034955836735742333 \tp(spam)= 0.002713788932137246\n",
      "Exemple 67 : p(ham)= 0.00307366192066041 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 68 : p(ham)= 0.003628592247802017 \tp(spam)= 0.002641425573375015\n",
      "Exemple 69 : p(ham)= 0.003086442201331834 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 70 : p(ham)= 0.003325791972871089 \tp(spam)= 0.002307543701696923\n",
      "Exemple 71 : p(ham)= 0.003177404534930269 \tp(spam)= 0.002307543701696923\n",
      "Exemple 72 : p(ham)= 0.0033120205972562403 \tp(spam)= 0.002307543701696923\n",
      "Exemple 73 : p(ham)= 0.0031251027703979384 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 74 : p(ham)= 0.00370466060699702 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 75 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.002370760176326591\n",
      "Exemple 76 : p(ham)= 0.0031511451434019276 \tp(spam)= 0.002246012898483751\n",
      "Exemple 77 : p(ham)= 0.0031251027703979384 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 78 : p(ham)= 0.004265973843646684 \tp(spam)= 0.003191554015975859\n",
      "Exemple 79 : p(ham)= 0.0035101183041262906 \tp(spam)= 0.002246012898483751\n",
      "Exemple 80 : p(ham)= 0.003466694717416663 \tp(spam)= 0.002570991788290878\n",
      "Exemple 81 : p(ham)= 0.004446708967079718 \tp(spam)= 0.003278988456906181\n",
      "Exemple 82 : p(ham)= 0.004319409147358295 \tp(spam)= 0.004181952408207202\n",
      "Exemple 83 : p(ham)= 0.0033396206098406777 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 84 : p(ham)= 0.0031380969420289383 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 85 : p(ham)= 0.0034238083228240405 \tp(spam)= 0.002370760176326591\n",
      "Exemple 86 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 87 : p(ham)= 0.003643679927763611 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 88 : p(ham)= 0.0038456246551643106 \tp(spam)= 0.002370760176326591\n",
      "Exemple 89 : p(ham)= 0.003628592247802017 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 90 : p(ham)= 0.005471939611113812 \tp(spam)= 0.0029429923487623044\n",
      "Exemple 91 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.002246012898483751\n",
      "Exemple 92 : p(ham)= 0.003409631082987193 \tp(spam)= 0.002307543701696923\n",
      "Exemple 93 : p(ham)= 0.003782323632904472 \tp(spam)= 0.002307543701696923\n",
      "Exemple 94 : p(ham)= 0.0035393691214210287 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 95 : p(ham)= 0.003244014375045899 \tp(spam)= 0.002246012898483751\n",
      "Exemple 96 : p(ham)= 0.0044099595162321896 \tp(spam)= 0.003653344632392845\n",
      "Exemple 97 : p(ham)= 0.00389379469298946 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 98 : p(ham)= 0.003353506746257615 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 99 : p(ham)= 0.00440995951623219 \tp(spam)= 0.0031064510201119873\n",
      "Exemple 100 : p(ham)= 0.0035247133696457277 \tp(spam)= 0.002713788932137246\n",
      "Exemple 101 : p(ham)= 0.0037200645790576876 \tp(spam)= 0.002307543701696923\n",
      "Exemple 102 : p(ham)= 0.004195753650712898 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 103 : p(ham)= 0.004319409147358295 \tp(spam)= 0.0042965193774574485\n",
      "Exemple 104 : p(ham)= 0.0038616147554806743 \tp(spam)= 0.002570991788290878\n",
      "Exemple 105 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.002246012898483751\n",
      "Exemple 106 : p(ham)= 0.003230581622539686 \tp(spam)= 0.002307543701696923\n",
      "Exemple 107 : p(ham)= 0.0034811092277416016 \tp(spam)= 0.002307543701696923\n",
      "Exemple 108 : p(ham)= 0.0034380445115983244 \tp(spam)= 0.002246012898483751\n",
      "Exemple 109 : p(ham)= 0.0036740437521743806 \tp(spam)= 0.003023617301179902\n",
      "Exemple 110 : p(ham)= 0.0033955125479931524 \tp(spam)= 0.002570991788290878\n",
      "Exemple 111 : p(ham)= 0.0039919524505094605 \tp(spam)= 0.003753430090404869\n",
      "Exemple 112 : p(ham)= 0.003244014375045899 \tp(spam)= 0.002246012898483751\n",
      "Exemple 113 : p(ham)= 0.003568863694121789 \tp(spam)= 0.002307543701696923\n",
      "Exemple 114 : p(ham)= 0.0031511451434019276 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 115 : p(ham)= 0.00389379469298946 \tp(spam)= 0.002370760176326591\n",
      "Exemple 116 : p(ham)= 0.0039919524505094605 \tp(spam)= 0.002788134726348021\n",
      "Exemple 117 : p(ham)= 0.004092584643925812 \tp(spam)= 0.002864517265956117\n",
      "Exemple 118 : p(ham)= 0.0035101183041262906 \tp(spam)= 0.002307543701696923\n",
      "Exemple 119 : p(ham)= 0.003230581622539686 \tp(spam)= 0.002370760176326591\n",
      "Exemple 120 : p(ham)= 0.004075638147925218 \tp(spam)= 0.003023617301179902\n",
      "Exemple 121 : p(ham)= 0.003568863694121789 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 122 : p(ham)= 0.0035247133696457277 \tp(spam)= 0.002641425573375015\n",
      "Exemple 123 : p(ham)= 0.003409631082987193 \tp(spam)= 0.002307543701696923\n",
      "Exemple 124 : p(ham)= 0.003568863694121789 \tp(spam)= 0.0035559279596423564\n",
      "Exemple 125 : p(ham)= 0.003284648682645691 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 126 : p(ham)= 0.004465198374870933 \tp(spam)= 0.003653344632392845\n",
      "Exemple 127 : p(ham)= 0.003086442201331834 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 128 : p(ham)= 0.0031380969420289383 \tp(spam)= 0.002246012898483751\n",
      "Exemple 129 : p(ham)= 0.004502408146887611 \tp(spam)= 0.002788134726348021\n",
      "Exemple 130 : p(ham)= 0.004161078198890721 \tp(spam)= 0.003191554015975859\n",
      "Exemple 131 : p(ham)= 0.003367450621204499 \tp(spam)= 0.002246012898483751\n",
      "Exemple 132 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 133 : p(ham)= 0.003325791972871089 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 134 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.002307543701696923\n",
      "Exemple 135 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.002246012898483751\n",
      "Exemple 136 : p(ham)= 0.0037823236329044725 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 137 : p(ham)= 0.003367450621204499 \tp(spam)= 0.002307543701696923\n",
      "Exemple 138 : p(ham)= 0.004025218529217368 \tp(spam)= 0.002788134726348021\n",
      "Exemple 139 : p(ham)= 0.004483764661586088 \tp(spam)= 0.0033688182141690883\n",
      "Exemple 140 : p(ham)= 0.0038138428148664022 \tp(spam)= 0.004181952408207202\n",
      "Exemple 141 : p(ham)= 0.0035393691214210287 \tp(spam)= 0.002641425573375015\n",
      "Exemple 142 : p(ham)= 0.003112162404783608 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 143 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 144 : p(ham)= 0.003877671342605049 \tp(spam)= 0.0038562574465714383\n",
      "Exemple 145 : p(ham)= 0.004143848086091389 \tp(spam)= 0.002570991788290878\n",
      "Exemple 146 : p(ham)= 0.003244014375045899 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 147 : p(ham)= 0.0034523398944196187 \tp(spam)= 0.002307543701696923\n",
      "Exemple 148 : p(ham)= 0.003325791972871089 \tp(spam)= 0.002370760176326591\n",
      "Exemple 149 : p(ham)= 0.0034811092277416016 \tp(spam)= 0.002370760176326591\n",
      "Exemple 150 : p(ham)= 0.003877671342605049 \tp(spam)= 0.002570991788290878\n",
      "Exemple 151 : p(ham)= 0.0047322696483752666 \tp(spam)= 0.004659398343189487\n",
      "Exemple 152 : p(ham)= 0.003942568105494185 \tp(spam)= 0.0031064510201119873\n",
      "Exemple 153 : p(ham)= 0.003583703022865899 \tp(spam)= 0.002713788932137246\n",
      "Exemple 154 : p(ham)= 0.003244014375045899 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 155 : p(ham)= 0.0030609345603300727 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 156 : p(ham)= 0.004301523420804227 \tp(spam)= 0.002788134726348021\n",
      "Exemple 157 : p(ham)= 0.0031511451434019276 \tp(spam)= 0.002246012898483751\n",
      "Exemple 158 : p(ham)= 0.0038616147554806743 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 159 : p(ham)= 0.0035540858117855344 \tp(spam)= 0.002307543701696923\n",
      "Exemple 160 : p(ham)= 0.003353506746257615 \tp(spam)= 0.002307543701696923\n",
      "Exemple 161 : p(ham)= 0.0041266893194126745 \tp(spam)= 0.002641425573375015\n",
      "Exemple 162 : p(ham)= 0.003735532600806145 \tp(spam)= 0.003278988456906181\n",
      "Exemple 163 : p(ham)= 0.003466694717416663 \tp(spam)= 0.002307543701696923\n",
      "Exemple 164 : p(ham)= 0.003325791972871089 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 165 : p(ham)= 0.003643679927763611 \tp(spam)= 0.002370760176326591\n",
      "Exemple 166 : p(ham)= 0.0034523398944196187 \tp(spam)= 0.002246012898483751\n",
      "Exemple 167 : p(ham)= 0.003409631082987193 \tp(spam)= 0.002307543701696923\n",
      "Exemple 168 : p(ham)= 0.004558805010905161 \tp(spam)= 0.002713788932137246\n",
      "Exemple 169 : p(ham)= 0.004230718062968307 \tp(spam)= 0.003023617301179902\n",
      "Exemple 170 : p(ham)= 0.004465198374870933 \tp(spam)= 0.002713788932137246\n",
      "Exemple 171 : p(ham)= 0.0033955125479931524 \tp(spam)= 0.002307543701696923\n",
      "Exemple 172 : p(ham)= 0.0036588303422710237 \tp(spam)= 0.002370760176326591\n",
      "Exemple 173 : p(ham)= 0.003735532600806145 \tp(spam)= 0.0029429923487623044\n",
      "Exemple 174 : p(ham)= 0.004391698840447384 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 175 : p(ham)= 0.0036740437521743806 \tp(spam)= 0.003023617301179902\n",
      "Exemple 176 : p(ham)= 0.0037980505276855006 \tp(spam)= 0.002788134726348021\n",
      "Exemple 177 : p(ham)= 0.003583703022865899 \tp(spam)= 0.002246012898483751\n",
      "Exemple 178 : p(ham)= 0.0035247133696457277 \tp(spam)= 0.0035559279596423564\n",
      "Exemple 179 : p(ham)= 0.0035393691214210287 \tp(spam)= 0.002370760176326591\n",
      "Exemple 180 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.004787045215894498\n",
      "Exemple 181 : p(ham)= 0.003926242795098715 \tp(spam)= 0.002641425573375015\n",
      "Exemple 182 : p(ham)= 0.004502408146887611 \tp(spam)= 0.0031064510201119873\n",
      "Exemple 183 : p(ham)= 0.003628592247802017 \tp(spam)= 0.002370760176326591\n",
      "Exemple 184 : p(ham)= 0.0035101183041262906 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 185 : p(ham)= 0.003112162404783608 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 186 : p(ham)= 0.003284648682645691 \tp(spam)= 0.0035559279596423564\n",
      "Exemple 187 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.002246012898483751\n",
      "Exemple 188 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 189 : p(ham)= 0.0031511451434019276 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 190 : p(ham)= 0.003284648682645691 \tp(spam)= 0.002307543701696923\n",
      "Exemple 191 : p(ham)= 0.003244014375045899 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 192 : p(ham)= 0.004109601603425929 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 193 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.002307543701696923\n",
      "Exemple 194 : p(ham)= 0.0031511451434019276 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 195 : p(ham)= 0.0031642475991724758 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 196 : p(ham)= 0.0035540858117855344 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 197 : p(ham)= 0.00435540401614721 \tp(spam)= 0.0029429923487623044\n",
      "Exemple 198 : p(ham)= 0.003926242795098715 \tp(spam)= 0.002307543701696923\n",
      "Exemple 199 : p(ham)= 0.0032983062458894117 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 200 : p(ham)= 0.003598604053511916 \tp(spam)= 0.002570991788290878\n",
      "Exemple 201 : p(ham)= 0.004596794833726678 \tp(spam)= 0.002641425573375015\n",
      "Exemple 202 : p(ham)= 0.003230581622539686 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 203 : p(ham)= 0.0036740437521743806 \tp(spam)= 0.003023617301179902\n",
      "Exemple 204 : p(ham)= 0.0039919524505094605 \tp(spam)= 0.002641425573375015\n",
      "Exemple 205 : p(ham)= 0.0033396206098406777 \tp(spam)= 0.002307543701696923\n",
      "Exemple 206 : p(ham)= 0.003086442201331834 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 207 : p(ham)= 0.0035101183041262906 \tp(spam)= 0.002307543701696923\n",
      "Exemple 208 : p(ham)= 0.0031380969420289383 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 209 : p(ham)= 0.003909985084235421 \tp(spam)= 0.002788134726348021\n",
      "Exemple 210 : p(ham)= 0.003177404534930269 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 211 : p(ham)= 0.003112162404783608 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 212 : p(ham)= 0.00435540401614721 \tp(spam)= 0.002713788932137246\n",
      "Exemple 213 : p(ham)= 0.0037666618597477224 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 214 : p(ham)= 0.003325791972871089 \tp(spam)= 0.002370760176326591\n",
      "Exemple 215 : p(ham)= 0.003628592247802017 \tp(spam)= 0.002570991788290878\n",
      "Exemple 216 : p(ham)= 0.003735532600806145 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 217 : p(ham)= 0.003177404534930269 \tp(spam)= 0.002246012898483751\n",
      "Exemple 218 : p(ham)= 0.0032983062458894117 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 219 : p(ham)= 0.004539927998550767 \tp(spam)= 0.0031064510201119873\n",
      "Exemple 220 : p(ham)= 0.003325791972871089 \tp(spam)= 0.002246012898483751\n",
      "Exemple 221 : p(ham)= 0.0031906161772029948 \tp(spam)= 0.002307543701696923\n",
      "Exemple 222 : p(ham)= 0.0038456246551643106 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 223 : p(ham)= 0.003177404534930269 \tp(spam)= 0.002246012898483751\n",
      "Exemple 224 : p(ham)= 0.004058761823650243 \tp(spam)= 0.002864517265956117\n",
      "Exemple 225 : p(ham)= 0.0033120205972562403 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 226 : p(ham)= 0.003735532600806145 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 227 : p(ham)= 0.0035247133696457277 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 228 : p(ham)= 0.0036893204194084245 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 229 : p(ham)= 0.003877671342605049 \tp(spam)= 0.0024357085023017683\n",
      "Exemple 230 : p(ham)= 0.0032172044921174206 \tp(spam)= 0.002788134726348021\n",
      "Exemple 231 : p(ham)= 0.004319409147358295 \tp(spam)= 0.0025024361246769357\n",
      "Exemple 232 : p(ham)= 0.0036135670426162363 \tp(spam)= 0.002713788932137246\n",
      "Exemple 233 : p(ham)= 0.0033120205972562403 \tp(spam)= 0.002246012898483751\n",
      "Exemple 234 : p(ham)= 0.004391698840447384 \tp(spam)= 0.002713788932137246\n",
      "Exemple 235 : p(ham)= 0.0034811092277416016 \tp(spam)= 0.002246012898483751\n",
      "Exemple 236 : p(ham)= 0.0031251027703979384 \tp(spam)= 0.0021861228181488824\n",
      "Exemple 237 : p(ham)= 0.0034238083228240405 \tp(spam)= 0.002370760176326591\n",
      "Exemple 238 : p(ham)= 0.0033814524747580307 \tp(spam)= 0.002307543701696923\n",
      "Exemple 239 : p(ham)= 0.0036135670426162363 \tp(spam)= 0.003023617301179902\n",
      "Exemple 240 : p(ham)= 0.003583703022865899 \tp(spam)= 0.002246012898483751\n",
      "Exemple 241 : p(ham)= 0.003325791972871089 \tp(spam)= 0.015303407531642985\n",
      "Exemple 242 : p(ham)= 0.0035393691214210287 \tp(spam)= 0.00757893596192746\n",
      "Exemple 243 : p(ham)= 0.003735532600806145 \tp(spam)= 0.013735275944859893\n",
      "Exemple 244 : p(ham)= 0.0036135670426162363 \tp(spam)= 0.0064443943069429355\n",
      "Exemple 245 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.010482394542875018\n",
      "Exemple 246 : p(ham)= 0.0034523398944196187 \tp(spam)= 0.013012538022377822\n",
      "Exemple 247 : p(ham)= 0.003598604053511916 \tp(spam)= 0.013012538022377822\n",
      "Exemple 248 : p(ham)= 0.0033814524747580307 \tp(spam)= 0.004918189047415059\n",
      "Exemple 249 : p(ham)= 0.0033955125479931524 \tp(spam)= 0.011064604104263144\n",
      "Exemple 250 : p(ham)= 0.0034238083228240405 \tp(spam)= 0.014111561656225275\n",
      "Exemple 251 : p(ham)= 0.003598604053511916 \tp(spam)= 0.01615338414245446\n",
      "Exemple 252 : p(ham)= 0.0046159082982782235 \tp(spam)= 0.010482394542875018\n",
      "Exemple 253 : p(ham)= 0.0033120205972562403 \tp(spam)= 0.013735275944859899\n",
      "Exemple 254 : p(ham)= 0.0035540858117855344 \tp(spam)= 0.015303407531642988\n",
      "Exemple 255 : p(ham)= 0.003112162404783608 \tp(spam)= 0.002788134726348021\n",
      "Exemple 256 : p(ham)= 0.003466694717416663 \tp(spam)= 0.00610529604843301\n",
      "Exemple 257 : p(ham)= 0.0034811092277416016 \tp(spam)= 0.010482394542875018\n",
      "Exemple 258 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.01020288080913895\n",
      "Exemple 259 : p(ham)= 0.00389379469298946 \tp(spam)= 0.00757893596192746\n",
      "Exemple 260 : p(ham)= 0.0034238083228240405 \tp(spam)= 0.013012538022377824\n",
      "Exemple 261 : p(ham)= 0.004008550981532523 \tp(spam)= 0.010769565714623805\n",
      "Exemple 262 : p(ham)= 0.0035101183041262906 \tp(spam)= 0.010202880809138944\n",
      "Exemple 263 : p(ham)= 0.0034380445115983244 \tp(spam)= 0.0039619018167549305\n",
      "Exemple 264 : p(ham)= 0.0036588303422710237 \tp(spam)= 0.013012538022377822\n",
      "Exemple 265 : p(ham)= 0.003244014375045899 \tp(spam)= 0.008219043966011705\n",
      "Exemple 266 : p(ham)= 0.0035393691214210287 \tp(spam)= 0.011064604104263144\n",
      "Exemple 267 : p(ham)= 0.003409631082987193 \tp(spam)= 0.0064443943069429355\n",
      "Exemple 268 : p(ham)= 0.00435540401614721 \tp(spam)= 0.017997586764150125\n",
      "Exemple 269 : p(ham)= 0.0035247133696457277 \tp(spam)= 0.008675543286172665\n",
      "Exemple 270 : p(ham)= 0.0032710476723779073 \tp(spam)= 0.0062725541126978646\n",
      "Exemple 271 : p(ham)= 0.0032575029809125823 \tp(spam)= 0.006802326644588789\n",
      "Exemple 272 : p(ham)= 0.0033955125479931524 \tp(spam)= 0.0039619018167549305\n",
      "Exemple 273 : p(ham)= 0.00435540401614721 \tp(spam)= 0.018997202553571332\n",
      "Exemple 274 : p(ham)= 0.003466694717416663 \tp(spam)= 0.007578935961927458\n",
      "Exemple 275 : p(ham)= 0.003628592247802017 \tp(spam)= 0.013735275944859897\n",
      "Exemple 276 : p(ham)= 0.0032172044921174206 \tp(spam)= 0.01076956571462381\n",
      "Exemple 277 : p(ham)= 0.003782323632904472 \tp(spam)= 0.005479689786532598\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df_train)):\n",
    "    p_spam = toutes_probas['spam'][i]\n",
    "    p_ham = toutes_probas['ham'][i]\n",
    "    if (p_spam>0) and (p_ham>0):\n",
    "        print(\"Exemple\",i,\": p(ham)=\",p_ham,\"\\tp(spam)=\",p_spam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> En utilisant les fonctions écrites, calculer le taux de bonne prédiction du classifieur bayésien naïf pour chaque valeur de label pour le dataset d'apprentissage. \n",
    "\n",
    "*Remarque*: une solution efficace peut ne pas utiliser toutes les fonctions précédentes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats des classements :  {'ham': {True: 241, False: 0, 'Taux': 1.0}, 'spam': {True: 37, False: 0, 'Taux': 1.0}}\n",
      "Temps:  3.3476459980010986\n"
     ]
    }
   ],
   "source": [
    "# La variable suivante permettra de stocker les résultats\n",
    "taux = dict()\n",
    "toutes_probas = dict()\n",
    "for l in les_labels:\n",
    "    taux[l] = dict()\n",
    "    taux[l][True] = 0    # nombre de bien classés\n",
    "    taux[l][False] = 0   # nombre de mal classés\n",
    "    toutes_probas[l] = np.zeros(1)\n",
    "tic = time.time()\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    exemple = row[\"les_mots\"]\n",
    "    vrai_label = row[\"label\"]\n",
    "\n",
    "    probabilites = {}\n",
    "    for label in les_labels:\n",
    "        probabilites[label] = proba_exemple(exemple, label, index_mots, frequences)\n",
    "\n",
    "    # Trouver le label avec la probabilité la plus élevée\n",
    "    predicted_label = max(probabilites, key=probabilites.get)\n",
    "\n",
    "    toutes_probas[predicted_label] = np.append(toutes_probas[predicted_label], probabilites[predicted_label])\n",
    "\n",
    "    for l in les_labels:\n",
    "        if l == vrai_label:\n",
    "            if l == predicted_label:\n",
    "                taux[l][True] += 1  # bien classé\n",
    "            else:\n",
    "                taux[l][False] += 1  # mal classé\n",
    "\n",
    "    for l in les_labels:\n",
    "        total = taux[l][True] + taux[l][False]\n",
    "        taux[l]['Taux'] = taux[l][True] / total if total != 0 else 0\n",
    "# #############################################\n",
    "toc = time.time()\n",
    "print(\"Résultats des classements : \", taux)\n",
    "\n",
    "print(\"Temps: \",toc-tic)\n",
    "# le résultat total peut prendre un certain temps...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Même question pour calculer le taux de bonne classification pour le dataset de test.\n",
    "\n",
    "*Remarque*: L'index des mots ainsi que la matrice des fréquences restent les mêmes, ce sont toujours celles construites à partir de la base d'apprentissage. Par contre, la matrice des présences doit, elle, être recalculées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats des classements :  {'ham': {True: 4552, False: 32, 'Taux': 0.9930191972076788}, 'spam': {True: 195, False: 515, 'Taux': 0.2746478873239437}}\n",
      "Temps:  63.77068781852722\n"
     ]
    }
   ],
   "source": [
    "# La variable suivante permettra de stocker les résultats\n",
    "taux = dict()\n",
    "toutes_probas = dict()\n",
    "for l in les_labels:\n",
    "    taux[l] = dict()\n",
    "    taux[l][True] = 0    # nombre de bien classés\n",
    "    taux[l][False] = 0   # nombre de mal classés\n",
    "    toutes_probas[l] = np.zeros(1)\n",
    "tic = time.time()\n",
    "\n",
    "mat_train = df2array(df_test, index_mots)\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    exemple = row[\"les_mots\"]\n",
    "    vrai_label = row[\"label\"]\n",
    "\n",
    "    probabilites = {}\n",
    "    for label in les_labels:\n",
    "        probabilites[label] = proba_exemple(exemple, label, index_mots, frequences)\n",
    "\n",
    "    # Trouver le label avec la probabilité la plus élevée\n",
    "    predicted_label = max(probabilites, key=probabilites.get)\n",
    "\n",
    "    toutes_probas[predicted_label] = np.append(toutes_probas[predicted_label], probabilites[predicted_label])\n",
    "\n",
    "    for l in les_labels:\n",
    "        if l == vrai_label:\n",
    "            if l == predicted_label:\n",
    "                taux[l][True] += 1  # bien classé\n",
    "            else:\n",
    "                taux[l][False] += 1  # mal classé\n",
    "\n",
    "    for l in les_labels:\n",
    "        total = taux[l][True] + taux[l][False]\n",
    "        taux[l]['Taux'] = taux[l][True] / total if total != 0 else 0\n",
    "\n",
    "\n",
    "# #############################################\n",
    "toc = time.time()\n",
    "print(\"Résultats des classements : \", taux)\n",
    "\n",
    "print(\"Temps: \",toc-tic)\n",
    "# le résultat total peut prendre un certain temps...\n",
    "\n",
    "\n",
    "# Il reste à calculer les taux de bonne classification par label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du classifieur Naive Bayes\n",
    "\n",
    "Pour tout ce que l'on a fait jusque-là, on a travaillé sur tout le dataset, pour pouvoir l'évaluer il est nécessaire de le séparer en ensemble d'apprentissage et ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Découper aléatoirement `df_spam` en 2 parties égales, chacune contenant des exemples des 2 labels, avec la même distribution des labels dans chaque partie. \n",
    "Une des parties sert à apprendre l'index des mots et leurs fréquences.\n",
    "L'autre partie n'est utilisée que pour calculer le taux de bonne classification par label.\n",
    "\n",
    "Donner ensuite les taux de bonne classification par label pour l'ensemble de train et pour l'ensemble de test.\n",
    "\n",
    "*Remarque*: certains mots de la partie de test pourront ne pas être présents dans l'index de mots car ils peuvent être absents de la partie d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Mettre en place une approche par validation croisée pour évaluer le taux de bonne classification moyen de cette approche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Comparer les résultats obtenus (taux de bonne classification avec la validation croisée, temps de calcul) avec ceux obtenus avec l'application d'un classifieur par $k$ plus proches voisins. Pour cela, la `mat_spam` doit être utilisée comme description des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
